# データのインポート {#sec-data-import}

```{r}
#| echo: false

source("_common.R")
```

## はじめに

Rパッケージが提供するデータで作業することは、データサイエンス道具を学習するのには向いていますが、どこかの時点で、あなたが持つデータに学習したことを応用したくなります。
本章では、データ・ファイルをRに読み込む基礎を学習します。

特に、本章は矩形のテキストだけのファイルを読み込むことにフォーカスします。
列の名前、型や欠損値などの特徴を扱うための実務的な助言からはじめます。
それから、複数のファイルから一度にデータを読み込むことや、データをRからファイルに書き出すことを学習します。
最後に、Rの中でデータフレームを手作りする方法を学習します。

### 準備するもの

本章では、tidyverseのコアの一部である、**readr**パッケージを使って、平坦なファイルをRにロードする方法を学習します。

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

## ファイルからデータを読み込む

最初は、最もよくある矩形データのファイル・タイプであるCSV (comma-separated values の略称です) にフォーカスします。
以下が簡単なCSVファイルの例です。
最初の行は、ヘッダー行と通常呼ばれ、列名が並びます。そ
の下の6行がデータです。
コンマが列名の区切り (delimiter) になっています。

```{r}
#| echo: false
#| message: false
#| comment: ""

read_lines("data/students.csv") |> cat(sep = "\n")
```

@tbl-students-table は、同じデータを表にしたものです。

```{r}
#| label: tbl-students-table
#| echo: false
#| message: false
#| tbl-cap: Data from the students.csv file as a table.

read_csv("data/students.csv") |>
  knitr::kable()
```

`read_csv()`を使って、このファイルをRに読み込めます。
第1引数が最も大事で、ファイルへのパスを指定します。
パスはファイルの住所と考えられます。こ
のファイルは名前が`students.csv`で、`data`フォルダの中に住んでいます。

```{r}
#| message: true

students <- read_csv("data/students.csv")
```

上記コードが機能するのは、あなたのプロジェクトの中の`data`フォルダの中に`students.csv`が入っている場合です。
`students.csv`は<https://pos.it/r4ds-students-csv>からダウンロードできます。も
しくは、以下のようにURLから直接読み込むこともできます。

```{r}
#| eval: false

students <- read_csv("https://pos.it/r4ds-students-csv")
```

`read_csv()`を実行すると、データの行数と列数、使用されたdelimiter、列の仕様 (列が含むデータの型ごとに整頓された列名) が、メッセージとしてプリントされます。
列の仕様の全てを引き出すことに関する情報もいくつかプリントすると同時に、そのメッセージをプリントさせない方法も示唆します。
このメッセージはreadrの統合された一部であり、@sec-col-types で戻ってきます。

### 実務的な助言

いったんデータを読み込んでしまえば、次の最初のステップは普通、後の分析で作業しやすい形式に変換することです。
そのことを心に留めて、`students`データを今一度見てみましょう。

```{r}
students
```

`favourite.food`列には食べ物が並んでいますが、中には`N/A`という文字列があります。本
来、Rが"not available"と認識する本物の`NA`であるべきだったものです。
`na`引数を使うことで、正すことができます。
デフォルトでは、このデータ中では空の文字列 (`""`) だけを`read_csv()`は`NA`と認識します。こ
こでは`"N/A"`という文字列も認識させます。

```{r}
#| message: false
students <- read_csv("data/students.csv", na = c("N/A", ""))

students
```

`Student ID`と`Full Name`の列名がバッククォートで囲まれていることにも、あなたは気付いたかもしれません。
列名にスペースがあり、変数名についてのRの普通の規則を破っているせいです。こ
れらは、**掟破りな**名前なのです。
これらの変数を指すには、バッククォートで囲む `` ` ``必要があります。

```{r}
students |> 
  rename(
    student_id = `Student ID`,
    full_name = `Full Name`
  )
```

別のやり方は、`janitor::clean_names()`を使うことです。い
くつかの経験則に沿って、これらを snake case に一挙に変えてくれます[^data-import-1]。

[^data-import-1]: [janitor](http://sfirke.github.io/janitor/)パッケージはtidyverseの一部ではありませんが、データ・クリーニングのための使い勝手の良い関数を提供してくれますし、`|>`を使ったパイプラインでの上手く機能します。

```{r}
#| message: false

students |> janitor::clean_names()
```

データを読み込んでからよくあるもう一つの仕事は、変数の型を検討することです。
例えば、`meal_plan`は限られた値だけを取るカテゴリ変数であり、Rではファクタとして表されるべきです。

```{r}
students |>
  janitor::clean_names() |>
  mutate(meal_plan = factor(meal_plan))
```

`meal_plan`変数の値は同じままですが、変数名の下に表示される変数の型は文字列 (`<chr>`) からファクタ (`<fct>`) に変わっています。
ファクタについては、@sec-factors でさらに学習します。

このデータを分析する前に、おそらく`age`列も修正したいでしょう。
このままだと、`age`は文字列変数です。
観測の1つで、数字の`5`ではなく`five`と入力されたせいです。
この件の修正に関する詳細は @sec-import-spreadsheets で議論します。

```{r}
students <- students |>
  janitor::clean_names() |>
  mutate(
    meal_plan = factor(meal_plan),
    age = parse_number(if_else(age == "five", "5", age))
  )

students
```

ここで新しく出て来た関数は`if_else()`で、3つの引数があります。
第1引数`test`は論理ベクトルでなければなりません。
`test`が`TRUE`であれば第2引数`yes`の値を、`FALSE`であれば第3引数`no`の値を返します。
ここでは、もし`age`が文字列`"five"`であれば`"5"`にせよ、そうでなければ`age`のままにせよ、と言っています。
`if_else()`と論理ベクトルについては @sec-logicals でさらに学習します。

### その他の引数

その他にも述べておく必要がある重要な引数が2、3ありますが、その実演を容易にする使い勝手の良いトリックをまず紹介します。
CSVのような形式で文字列を作れば、`read_csv()`は読み込むことができます。

```{r}
#| message: false

read_csv(
  "a,b,c
  1,2,3
  4,5,6"
)
```

通常、`read_csv()`はデータの1行目を列名に使います。そ
れがとても一般的な慣行だからです。
しかし、ファイルの頭に数行のメタデータがあることも珍しくありません。
`skip = n`とすれば、最初の`n`行をスキップできます。あ
るいは、 `comment = "#"`とすれば、`#`ではじまる全ての行を落とせます。

```{r}
#| message: false

read_csv(
  "The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3",
  skip = 2
)

read_csv(
  "# A comment I want to skip
  x,y,z
  1,2,3",
  comment = "#"
)
```

データに列名が入っていないこともあります。
`col_names = FALSE`とすれば、1行目をヘッダーとして扱うのを止めて、列名は`X1`から`Xn`まで順番に付けていきます。

```{r}
#| message: false

read_csv(
  "1,2,3
  4,5,6",
  col_names = FALSE
)
```

もしくは、`col_names`で、列名に使う文字列ベクトルを指定することもできます。

```{r}
#| message: false

read_csv(
  "1,2,3
  4,5,6",
  col_names = c("x", "y", "z")
)
```

これらの引数を知っておけば、実務で出会う大半のCSVファイルを読み込めます。
(大半から漏れたCSVファイルでは、`.csv`を注意深く検査して、`read_csv()`のその他多くの引数についてのドキュメントを読む必要があります。)

### その他のファイル・タイプ

いったん`read_csv()`を修得すれば、readrの他の関数は単刀直入に使えます。ど
の関数を使うべきか知るだけのことです。

-   `read_csv2()`は、セミコロン区切りファイルを読み込む。
    フィールドの区切りに`,`ではなく`;`を使うファイル。小
    数点に`,`を使う国で一般的。

-   `read_tsv()`は、タブ区切りファイルを読み込む。

-   `read_delim()`は、どんな区切り (delimiter) のファイルも読み込む。d
    elimiterを指定しないと、自動的に推定する。

-   `read_fwf()`は、固定幅ファイルを読み込む。
    `fwf_widths()`でフィールド幅を、または、`fwf_positions()`でフィールドの位置を指定できる。

-   `read_table()`は、列がホワイト・スペースで区切られている固定幅ファイルのよくある変種を読み込む。

-   `read_log()`は、ウェブサーバー Apache スタイルのログ・ファイルを読み込む。

### 練習問題

1.  フィールドが"\|"で区切られているファイルを読み込むにはどの関数を使うか？

2.  `file`、`skip`、`comment`以外に、どんな引数が`read_csv()`と`read_tsv()`で共通か？

3.  `read_fwf()`で最も重要な引数は？

4.  CSVファイルの文字列の中にコンマが入っていることがある。
    問題が生じないよう、`"`か`'`のような引用符で囲む必要がある。 デフォルトでは、`read_csv()`は`"`を引用符と想定する。
    以下のテキストをデータフレームに読み込むため、指定する必要がある引数は何か？

    ```{r}
    #| eval: false

    "x,y\n1,'a,b'"
    ```

5.  以下の各インラインCSVファイルのどこがおかしいのか特定しなさい。
    このままコードを実行すると、どうなるか？

    ```{r}
    #| eval: false

    read_csv("a,b\n1,2,3\n4,5,6")
    read_csv("a,b,c\n1,2\n1,2,3,4")
    read_csv("a,b\n\"1")
    read_csv("a,b\n1,2\na,b")
    read_csv("a;b\n1;3")
    ```

6.  以下のデータフレームで、掟破りな名前を指す練習をしなさい。

    a.  `1`という変数を選択。
    b.  `1`対`2`の散布図を描く。
    c.  `3`という新しい列を作って、`2`割る`1`にする。
    d.  列名を`one`、`two`、`three`に変更。

    ```{r}
    annoying <- tibble(
      `1` = 1:10,
      `2` = `1` * 2 + rnorm(length(`1`))
    )
    ```

## 列の型を管理 {#sec-col-types}

CSVファイルには各変数の型 (論理、数値、文字列など) についての情報は含まれていません。で
すから、readrは型を推定しようとします。
このセッションでは、推定の働き方、それを失敗させるいくつかのよくある問題を解決する方法、そして、必要なら、列の型を自分で指定する方法について述べます。
最後に、readrが壊滅的に失敗して、ファイルの構造について、さらに洞察を得る必要がある場合に役立つ2、3の一般的な戦略に触れます。

### 型の推定

readrは経験則を用いて列の型を探し出します。
列ごとに、最初の行から最後の行まで欠損値は除いて均等に1,000[^data-import-2] 行の値を引き出します。
次に、以下の質問に従って働きます。

[^data-import-2]: `guess_max`引数を使えば、デフォルトの1000から変更できます。

-   (大文字小文字は無視して) `F`、`T`、`FALSE`、`TRUE`ばかりか？　そうなら論理。
-   (例えば、`1`、`-4.5`、`5e6`、`Inf`などの) 数値ばかりか？　そうなら数値。
-   ISO8601標準に合致するか？　そうなら日付か日付時間。(日付時間の詳細には @sec-creating-datetimes で戻ってきます)。
-   そのどれでもなければ、文字列。

以下の簡単な例で、その通りに働いているのが分かります。

```{r}
#| message: false

read_csv("
  logical,numeric,date,string
  TRUE,1,2021-01-15,abc
  false,4.5,2021-02-15,def
  T,Inf,2021-02-16,ghi
")
```

データセットがきれいなら、この経験則は上手くいきます。し
かし、実生活では、いろいろと奇妙で美しい失敗に出会うことでしょう。

### 欠損値、列の型と問題

列の型推定が失敗するよくある道筋は、列に予期せぬ値があり、より特定の型ではなく文字列にされてしまうことです。
最もよくある原因は欠損値で、readrが予期している`NA`以外で記録されている場合です。

この1列だけのCSVファイルを例としましょう。

```{r}
simple_csv <- "
  x
  10
  .
  20
  30"
```

何も追加で引数の指定をしないで読み込むと、`x`列の型は文字列になります。

```{r}
#| message: false

read_csv(simple_csv)
```

このとても小さいケースでは、簡単に`.`が欠損値と見て取れます。
しかし、数千行あって、その中のほんの2、3行に欠損値`.`が散らばっていたら、どうでしょう？
一つの方法は、readrに`x`列の型は数値だと指定して、どこで失敗するか見てみることです。
`col_types`引数でそうすることができます。C
SVファイルの列名と一致する名前を付けたリストで指定します。

```{r}
df <- read_csv(
  simple_csv, 
  col_types = list(x = col_double())
)
```

こうすれば、`read_csv()`は問題があることを報告し、`problems()`を使ってより深く探れることを伝えてくれます。

```{r}
problems(df)
```

行番3、列番1に問題があり、readrはdoubleを予期していたのに、`.`だったと教えてくれます。
これで、このデータセットは欠損値に`.`を使っているらしいと分かります。
だから次に`na = "."`と設定すると、自動推定は成功し、望み通り数値列が得られます。

```{r}
#| message: false

read_csv(simple_csv, na = ".")
```

### 列の型

readrは全部で9つの列の型を使えるよう提供してくれます。

-   `col_logical()`と`col_double()`は、論理と実数を読みます。通常readrが推定してくれるので、(上では使いましたが) 使う必要があることはまれです。
-   `col_integer()`は、整数を読みます。整数と実数は機能的に等価なので、本書ではほとんど区別しません。ただ、整数は実数の半分のメモリしか占拠しないので、明示的に整数を読むのが役に立つことがたまにあります。
-   `col_character()`は、文字列を読みます。数字の羅列でオブジェクトを表しているが、足したり引いたりする意味はない、数字によるIDが列の場合、明示的に指定すると役に立つかもしれません。例としては、電話番号、社会保障番号、クレジットカード番号などです。
-   `col_factor()`、`col_date()`、`col_datetime()`は、それぞれファクタ、日付、日付時間を作ります。こららについては、@sec-factors や @sec-dates-and-times でこれらのデータの型に至った際、さらに学習します。
-   `col_number()`は、数字以外の構成要素は無視して数値にしてくれるパーサーで、特に金額では役に立ちます。@sec-numbers でさらに学習します。
-   `col_skip()`は、指定された列をスキップして、結果に含まれないようにします。CSVファイルが巨大で、使いたいのはその内のいくつかの列だけの場合に、データを読み込むのが速くなるので、役立ちます。

デフォルトの列の型を変更することもできます。`l`
`ist()`から`cols()`に切り替えて、`.default`を指定します。

```{r}
another_csv <- "
x,y,z
1,2,3"

read_csv(
  another_csv, 
  col_types = cols(.default = col_character())
)
```

もう一つ役に立つヘルパー関数は`cols_only()`で、そこに指定した列だけを読み込みます。

```{r}
read_csv(
  another_csv,
  col_types = cols_only(x = col_character())
)
```

## Reading data from multiple files {#sec-readr-directory}

Sometimes your data is split across multiple files instead of being contained in a single file.
For example, you might have sales data for multiple months, with each month's data in a separate file: `01-sales.csv` for January, `02-sales.csv` for February, and `03-sales.csv` for March.
With `read_csv()` you can read these data in at once and stack them on top of each other in a single data frame.

```{r}
#| message: false

sales_files <- c("data/01-sales.csv", "data/02-sales.csv", "data/03-sales.csv")
read_csv(sales_files, id = "file")
```

Once again, the code above will work if you have the CSV files in a `data` folder in your project.
You can download these files from <https://pos.it/r4ds-01-sales>, <https://pos.it/r4ds-02-sales>, and <https://pos.it/r4ds-03-sales> or you can read them directly with:

```{r}
#| eval: false

sales_files <- c(
  "https://pos.it/r4ds-01-sales",
  "https://pos.it/r4ds-02-sales",
  "https://pos.it/r4ds-03-sales"
)
read_csv(sales_files, id = "file")
```

The `id` argument adds a new column called `file` to the resulting data frame that identifies the file the data come from.
This is especially helpful in circumstances where the files you're reading in do not have an identifying column that can help you trace the observations back to their original sources.

If you have many files you want to read in, it can get cumbersome to write out their names as a list.
Instead, you can use the base `list.files()` function to find the files for you by matching a pattern in the file names.
You'll learn more about these patterns in @sec-regular-expressions.

```{r}
sales_files <- list.files("data", pattern = "sales\\.csv$", full.names = TRUE)
sales_files
```

## Writing to a file {#sec-writing-to-a-file}

readr also comes with two useful functions for writing data back to disk: `write_csv()` and `write_tsv()`.
The most important arguments to these functions are `x` (the data frame to save) and `file` (the location to save it).
You can also specify how missing values are written with `na`, and if you want to `append` to an existing file.

```{r}
#| eval: false

write_csv(students, "students.csv")
```

Now let's read that csv file back in.
Note that the variable type information that you just set up is lost when you save to CSV because you're starting over with reading from a plain text file again:

```{r}
#| warning: false
#| message: false

students
write_csv(students, "students-2.csv")
read_csv("students-2.csv")
```

This makes CSVs a little unreliable for caching interim results---you need to recreate the column specification every time you load in.
There are two main alternatives:

1.  `write_rds()` and `read_rds()` are uniform wrappers around the base functions `readRDS()` and `saveRDS()`.
    These store data in R's custom binary format called RDS.
    This means that when you reload the object, you are loading the *exact same* R object that you stored.

    ```{r}
    write_rds(students, "students.rds")
    read_rds("students.rds")
    ```

2.  The arrow package allows you to read and write parquet files, a fast binary file format that can be shared across programming languages.
    We'll return to arrow in more depth in @sec-arrow.

    ```{r}
    #| eval: false

    library(arrow)
    write_parquet(students, "students.parquet")
    read_parquet("students.parquet")
    #> # A tibble: 6 × 5
    #>   student_id full_name        favourite_food     meal_plan             age
    #>        <dbl> <chr>            <chr>              <fct>               <dbl>
    #> 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4
    #> 2          2 Barclay Lynn     French fries       Lunch only              5
    #> 3          3 Jayendra Lyne    NA                 Breakfast and lunch     7
    #> 4          4 Leon Rossini     Anchovies          Lunch only             NA
    #> 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5
    #> 6          6 Güvenç Attila    Ice cream          Lunch only              6
    ```

Parquet tends to be much faster than RDS and is usable outside of R, but does require the arrow package.

```{r}
#| include: false
file.remove("students-2.csv")
file.remove("students.rds")
```

## Data entry

Sometimes you'll need to assemble a tibble "by hand" doing a little data entry in your R script.
There are two useful functions to help you do this which differ in whether you layout the tibble by columns or by rows.
`tibble()` works by column:

```{r}
tibble(
  x = c(1, 2, 5), 
  y = c("h", "m", "g"),
  z = c(0.08, 0.83, 0.60)
)
```

Laying out the data by column can make it hard to see how the rows are related, so an alternative is `tribble()`, short for **tr**ansposed t**ibble**, which lets you lay out your data row by row.
`tribble()` is customized for data entry in code: column headings start with `~` and entries are separated by commas.
This makes it possible to lay out small amounts of data in an easy to read form:

```{r}
tribble(
  ~x, ~y, ~z,
  1, "h", 0.08,
  2, "m", 0.83,
  5, "g", 0.60
)
```

## Summary

In this chapter, you've learned how to load CSV files with `read_csv()` and to do your own data entry with `tibble()` and `tribble()`.
You've learned how csv files work, some of the problems you might encounter, and how to overcome them.
We'll come to data import a few times in this book: @sec-import-spreadsheets from Excel and Google Sheets, @sec-import-databases will show you how to load data from databases, @sec-arrow from parquet files, @sec-rectangling from JSON, and @sec-scraping from websites.

We're just about at the end of this section of the book, but there's one important last topic to cover: how to get help.
So in the next chapter, you'll learn some good places to look for help, how to create a reprex to maximize your chances of getting good help, and some general advice on keeping up with the world of R.
