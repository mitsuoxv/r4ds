# データのインポート {#sec-data-import}

```{r}
#| echo: false

source("_common.R")
```

## はじめに

Rパッケージが提供するデータで作業することは、データサイエンス道具を学習するのには向いていますが、どこかの時点で、あなたが持つデータに学習したことを応用したくなります。
本章では、データ・ファイルをRに読み込む基礎を学習します。

特に、本章は矩形のテキストだけのファイルを読み込むことにフォーカスします。
列の名前、型や欠損値などの特徴を扱うための実務的な助言からはじめます。
それから、複数のファイルから一度にデータを読み込むことや、データをRからファイルに書き出すことを学習します。
最後に、Rの中でデータフレームを手作りする方法を学習します。

### 準備するもの

本章では、tidyverseのコアの一部である、**readr**パッケージを使って、平坦なファイルをRにロードする方法を学習します。

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

## ファイルからデータを読み込む

最初は、最もよくある矩形データのファイル・タイプであるCSV (comma-separated values の略称です) にフォーカスします。
以下が簡単なCSVファイルの例です。
最初の行は、ヘッダー行と通常呼ばれ、列名が並びます。そ
の下の6行がデータです。
コンマが列名の区切り (delimiter) になっています。

```{r}
#| echo: false
#| message: false
#| comment: ""

read_lines("data/students.csv") |> cat(sep = "\n")
```

@tbl-students-table は、同じデータを表にしたものです。

```{r}
#| label: tbl-students-table
#| echo: false
#| message: false
#| tbl-cap: Data from the students.csv file as a table.

read_csv("data/students.csv") |>
  knitr::kable()
```

`read_csv()`を使って、このファイルをRに読み込めます。
第1引数が最も大事で、ファイルへのパスを指定します。
パスはファイルの住所と考えられます。こ
のファイルは名前が`students.csv`で、`data`フォルダの中に住んでいます。

```{r}
#| message: true

students <- read_csv("data/students.csv")
```

上記コードが機能するのは、あなたのプロジェクトの中の`data`フォルダの中に`students.csv`が入っている場合です。
`students.csv`は<https://pos.it/r4ds-students-csv>からダウンロードできます。も
しくは、以下のようにURLから直接読み込むこともできます。

```{r}
#| eval: false

students <- read_csv("https://pos.it/r4ds-students-csv")
```

`read_csv()`を実行すると、データの行数と列数、使用されたdelimiter、列の仕様 (列が含むデータの型ごとに整頓された列名) が、メッセージとしてプリントされます。
列の仕様の全てを引き出すことに関する情報もいくつかプリントすると同時に、そのメッセージをプリントさせない方法も示唆します。
このメッセージはreadrの統合された一部であり、@sec-col-types で戻ってきます。

### 実務的な助言

いったんデータを読み込んでしまえば、次の最初のステップは普通、後の分析で作業しやすい形式に変換することです。
そのことを心に留めて、`students`データを今一度見てみましょう。

```{r}
students
```

`favourite.food`列には食べ物が並んでいますが、中には`N/A`という文字列があります。本
来、Rが"not available"と認識する本物の`NA`であるべきだったものです。
`na`引数を使うことで、正すことができます。
デフォルトでは、このデータ中では空の文字列 (`""`) だけを`read_csv()`は`NA`と認識します。こ
こでは`"N/A"`という文字列も認識させます。

```{r}
#| message: false
students <- read_csv("data/students.csv", na = c("N/A", ""))

students
```

`Student ID`と`Full Name`の列名がバッククォートで囲まれていることにも、あなたは気付いたかもしれません。
列名にスペースがあり、変数名についてのRの普通の規則を破っているせいです。こ
れらは、**掟破りな**名前なのです。
これらの変数を指すには、バッククォートで囲む `` ` ``必要があります。

```{r}
students |> 
  rename(
    student_id = `Student ID`,
    full_name = `Full Name`
  )
```

別のやり方は、`janitor::clean_names()`を使うことです。い
くつかの経験則に沿って、これらを snake case に一挙に変えてくれます[^data-import-1]。

[^data-import-1]: [janitor](http://sfirke.github.io/janitor/)パッケージはtidyverseの一部ではありませんが、データ・クリーニングのための使い勝手の良い関数を提供してくれますし、`|>`を使ったパイプラインでの上手く機能します。

```{r}
#| message: false

students |> janitor::clean_names()
```

データを読み込んでからよくあるもう一つの仕事は、変数の型を検討することです。
例えば、`meal_plan`は限られた値だけを取るカテゴリ変数であり、Rではファクタとして表されるべきです。

```{r}
students |>
  janitor::clean_names() |>
  mutate(meal_plan = factor(meal_plan))
```

`meal_plan`変数の値は同じままですが、変数名の下に表示される変数の型は文字列 (`<chr>`) からファクタ (`<fct>`) に変わっています。
ファクタについては、@sec-factors でさらに学習します。

このデータを分析する前に、おそらく`age`列も修正したいでしょう。
このままだと、`age`は文字列変数です。
観測の1つで、数字の`5`ではなく`five`と入力されたせいです。
この件の修正に関する詳細は @sec-import-spreadsheets で議論します。

```{r}
students <- students |>
  janitor::clean_names() |>
  mutate(
    meal_plan = factor(meal_plan),
    age = parse_number(if_else(age == "five", "5", age))
  )

students
```

ここで新しく出て来た関数は`if_else()`で、3つの引数があります。
第1引数`test`は論理ベクトルでなければなりません。
`test`が`TRUE`であれば第2引数`yes`の値を、`FALSE`であれば第3引数`no`の値を返します。
ここでは、もし`age`が文字列`"five"`であれば`"5"`にせよ、そうでなければ`age`のままにせよ、と言っています。
`if_else()`と論理ベクトルについては @sec-logicals でさらに学習します。

### その他の引数

その他にも述べておく必要がある重要な引数が2、3ありますが、その実演を容易にする使い勝手の良いトリックをまず紹介します。
CSVのような形式で文字列を作れば、`read_csv()`は読み込むことができます。

```{r}
#| message: false

read_csv(
  "a,b,c
  1,2,3
  4,5,6"
)
```

通常、`read_csv()`はデータの1行目を列名に使います。そ
れがとても一般的な慣行だからです。
しかし、ファイルの頭に数行のメタデータがあることも珍しくありません。
`skip = n`とすれば、最初の`n`行をスキップできます。あ
るいは、 `comment = "#"`とすれば、`#`ではじまる全ての行を落とせます。

```{r}
#| message: false

read_csv(
  "The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3",
  skip = 2
)

read_csv(
  "# A comment I want to skip
  x,y,z
  1,2,3",
  comment = "#"
)
```

データに列名が入っていないこともあります。
`col_names = FALSE`とすれば、1行目をヘッダーとして扱うのを止めて、列名は`X1`から`Xn`まで順番に付けていきます。

```{r}
#| message: false

read_csv(
  "1,2,3
  4,5,6",
  col_names = FALSE
)
```

もしくは、`col_names`で、列名に使う文字列ベクトルを指定することもできます。

```{r}
#| message: false

read_csv(
  "1,2,3
  4,5,6",
  col_names = c("x", "y", "z")
)
```

これらの引数を知っておけば、実務で出会う大半のCSVファイルを読み込めます。
(大半から漏れたCSVファイルでは、`.csv`を注意深く検査して、`read_csv()`のその他多くの引数についてのドキュメントを読む必要があります。)

### その他のファイル・タイプ

いったん`read_csv()`を修得すれば、readrの他の関数は単刀直入に使えます。ど
の関数を使うべきか知るだけのことです。

-   `read_csv2()`は、セミコロン区切りファイルを読み込む。
    フィールドの区切りに`,`ではなく`;`を使うファイル。小
    数点に`,`を使う国で一般的。

-   `read_tsv()`は、タブ区切りファイルを読み込む。

-   `read_delim()`は、どんな区切り (delimiter) のファイルも読み込む。d
    elimiterを指定しないと、自動的に推定する。

-   `read_fwf()`は、固定幅ファイルを読み込む。
    `fwf_widths()`でフィールド幅を、または、`fwf_positions()`でフィールドの位置を指定できる。

-   `read_table()`は、列がホワイト・スペースで区切られている固定幅ファイルのよくある変種を読み込む。

-   `read_log()`は、ウェブサーバー Apache スタイルのログ・ファイルを読み込む。

### 練習問題

1.  フィールドが"\|"で区切られているファイルを読み込むにはどの関数を使うか？

2.  `file`、`skip`、`comment`以外に、どんな引数が`read_csv()`と`read_tsv()`で共通か？

3.  `read_fwf()`で最も重要な引数は？

4.  CSVファイルの文字列の中にコンマが入っていることがある。
    問題が生じないよう、`"`か`'`のような引用符で囲む必要がある。 デフォルトでは、`read_csv()`は`"`を引用符と想定する。
    以下のテキストをデータフレームに読み込むため、指定する必要がある引数は何か？

    ```{r}
    #| eval: false

    "x,y\n1,'a,b'"
    ```

5.  以下の各インラインCSVファイルのどこがおかしいのか特定しなさい。
    このままコードを実行すると、どうなるか？

    ```{r}
    #| eval: false

    read_csv("a,b\n1,2,3\n4,5,6")
    read_csv("a,b,c\n1,2\n1,2,3,4")
    read_csv("a,b\n\"1")
    read_csv("a,b\n1,2\na,b")
    read_csv("a;b\n1;3")
    ```

6.  以下のデータフレームで、掟破りな名前を指す練習をしなさい。

    a.  `1`という変数を選択。
    b.  `1`対`2`の散布図を描く。
    c.  `3`という新しい列を作って、`2`割る`1`にする。
    d.  列名を`one`、`two`、`three`に変更。

    ```{r}
    annoying <- tibble(
      `1` = 1:10,
      `2` = `1` * 2 + rnorm(length(`1`))
    )
    ```

## 列の型を管理 {#sec-col-types}

CSVファイルには各変数の型 (論理、数値、文字列など) についての情報は含まれていません。で
すから、readrは型を推定しようとします。
このセッションでは、推定の働き方、それを失敗させるいくつかのよくある問題を解決する方法、そして、必要なら、列の型を自分で指定する方法について述べます。
最後に、readrが壊滅的に失敗して、ファイルの構造について、さらに洞察を得る必要がある場合に役立つ2、3の一般的な戦略に触れます。

### 型の推定

readr uses a heuristic to figure out the column types.
For each column, it pulls the values of 1,000[^data-import-2] rows spaced evenly from the first row to the last, ignoring missing values.
It then works through the following questions:

[^data-import-2]: You can override the default of 1000 with the `guess_max` argument.

-   Does it contain only `F`, `T`, `FALSE`, or `TRUE` (ignoring case)? If so, it's a logical.
-   Does it contain only numbers (e.g., `1`, `-4.5`, `5e6`, `Inf`)? If so, it's a number.
-   Does it match the ISO8601 standard? If so, it's a date or date-time. (We'll return to date-times in more detail in @sec-creating-datetimes).
-   Otherwise, it must be a string.

You can see that behavior in action in this simple example:

```{r}
#| message: false

read_csv("
  logical,numeric,date,string
  TRUE,1,2021-01-15,abc
  false,4.5,2021-02-15,def
  T,Inf,2021-02-16,ghi
")
```

This heuristic works well if you have a clean dataset, but in real life, you'll encounter a selection of weird and beautiful failures.

### Missing values, column types, and problems

The most common way column detection fails is that a column contains unexpected values, and you get a character column instead of a more specific type.
One of the most common causes for this is a missing value, recorded using something other than the `NA` that readr expects.

Take this simple 1 column CSV file as an example:

```{r}
simple_csv <- "
  x
  10
  .
  20
  30"
```

If we read it without any additional arguments, `x` becomes a character column:

```{r}
#| message: false

read_csv(simple_csv)
```

In this very small case, you can easily see the missing value `.`.
But what happens if you have thousands of rows with only a few missing values represented by `.`s sprinkled among them?
One approach is to tell readr that `x` is a numeric column, and then see where it fails.
You can do that with the `col_types` argument, which takes a named list where the names match the column names in the CSV file:

```{r}
df <- read_csv(
  simple_csv, 
  col_types = list(x = col_double())
)
```

Now `read_csv()` reports that there was a problem, and tells us we can find out more with `problems()`:

```{r}
problems(df)
```

This tells us that there was a problem in row 3, col 1 where readr expected a double but got a `.`.
That suggests this dataset uses `.` for missing values.
So then we set `na = "."`, the automatic guessing succeeds, giving us the numeric column that we want:

```{r}
#| message: false

read_csv(simple_csv, na = ".")
```

### Column types

readr provides a total of nine column types for you to use:

-   `col_logical()` and `col_double()` read logicals and real numbers. They're relatively rarely needed (except as above), since readr will usually guess them for you.
-   `col_integer()` reads integers. We seldom distinguish integers and doubles in this book because they're functionally equivalent, but reading integers explicitly can occasionally be useful because they occupy half the memory of doubles.
-   `col_character()` reads strings. This can be useful to specify explicitly when you have a column that is a numeric identifier, i.e., long series of digits that identifies an object but doesn't make sense to apply mathematical operations to. Examples include phone numbers, social security numbers, credit card numbers, etc.
-   `col_factor()`, `col_date()`, and `col_datetime()` create factors, dates, and date-times respectively; you'll learn more about those when we get to those data types in @sec-factors and @sec-dates-and-times.
-   `col_number()` is a permissive numeric parser that will ignore non-numeric components, and is particularly useful for currencies. You'll learn more about it in @sec-numbers.
-   `col_skip()` skips a column so it's not included in the result, which can be useful for speeding up reading the data if you have a large CSV file and you only want to use some of the columns.

It's also possible to override the default column by switching from `list()` to `cols()` and specifying `.default`:

```{r}
another_csv <- "
x,y,z
1,2,3"

read_csv(
  another_csv, 
  col_types = cols(.default = col_character())
)
```

Another useful helper is `cols_only()` which will read in only the columns you specify:

```{r}
read_csv(
  another_csv,
  col_types = cols_only(x = col_character())
)
```

## Reading data from multiple files {#sec-readr-directory}

Sometimes your data is split across multiple files instead of being contained in a single file.
For example, you might have sales data for multiple months, with each month's data in a separate file: `01-sales.csv` for January, `02-sales.csv` for February, and `03-sales.csv` for March.
With `read_csv()` you can read these data in at once and stack them on top of each other in a single data frame.

```{r}
#| message: false

sales_files <- c("data/01-sales.csv", "data/02-sales.csv", "data/03-sales.csv")
read_csv(sales_files, id = "file")
```

Once again, the code above will work if you have the CSV files in a `data` folder in your project.
You can download these files from <https://pos.it/r4ds-01-sales>, <https://pos.it/r4ds-02-sales>, and <https://pos.it/r4ds-03-sales> or you can read them directly with:

```{r}
#| eval: false

sales_files <- c(
  "https://pos.it/r4ds-01-sales",
  "https://pos.it/r4ds-02-sales",
  "https://pos.it/r4ds-03-sales"
)
read_csv(sales_files, id = "file")
```

The `id` argument adds a new column called `file` to the resulting data frame that identifies the file the data come from.
This is especially helpful in circumstances where the files you're reading in do not have an identifying column that can help you trace the observations back to their original sources.

If you have many files you want to read in, it can get cumbersome to write out their names as a list.
Instead, you can use the base `list.files()` function to find the files for you by matching a pattern in the file names.
You'll learn more about these patterns in @sec-regular-expressions.

```{r}
sales_files <- list.files("data", pattern = "sales\\.csv$", full.names = TRUE)
sales_files
```

## Writing to a file {#sec-writing-to-a-file}

readr also comes with two useful functions for writing data back to disk: `write_csv()` and `write_tsv()`.
The most important arguments to these functions are `x` (the data frame to save) and `file` (the location to save it).
You can also specify how missing values are written with `na`, and if you want to `append` to an existing file.

```{r}
#| eval: false

write_csv(students, "students.csv")
```

Now let's read that csv file back in.
Note that the variable type information that you just set up is lost when you save to CSV because you're starting over with reading from a plain text file again:

```{r}
#| warning: false
#| message: false

students
write_csv(students, "students-2.csv")
read_csv("students-2.csv")
```

This makes CSVs a little unreliable for caching interim results---you need to recreate the column specification every time you load in.
There are two main alternatives:

1.  `write_rds()` and `read_rds()` are uniform wrappers around the base functions `readRDS()` and `saveRDS()`.
    These store data in R's custom binary format called RDS.
    This means that when you reload the object, you are loading the *exact same* R object that you stored.

    ```{r}
    write_rds(students, "students.rds")
    read_rds("students.rds")
    ```

2.  The arrow package allows you to read and write parquet files, a fast binary file format that can be shared across programming languages.
    We'll return to arrow in more depth in @sec-arrow.

    ```{r}
    #| eval: false

    library(arrow)
    write_parquet(students, "students.parquet")
    read_parquet("students.parquet")
    #> # A tibble: 6 × 5
    #>   student_id full_name        favourite_food     meal_plan             age
    #>        <dbl> <chr>            <chr>              <fct>               <dbl>
    #> 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4
    #> 2          2 Barclay Lynn     French fries       Lunch only              5
    #> 3          3 Jayendra Lyne    NA                 Breakfast and lunch     7
    #> 4          4 Leon Rossini     Anchovies          Lunch only             NA
    #> 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5
    #> 6          6 Güvenç Attila    Ice cream          Lunch only              6
    ```

Parquet tends to be much faster than RDS and is usable outside of R, but does require the arrow package.

```{r}
#| include: false
file.remove("students-2.csv")
file.remove("students.rds")
```

## Data entry

Sometimes you'll need to assemble a tibble "by hand" doing a little data entry in your R script.
There are two useful functions to help you do this which differ in whether you layout the tibble by columns or by rows.
`tibble()` works by column:

```{r}
tibble(
  x = c(1, 2, 5), 
  y = c("h", "m", "g"),
  z = c(0.08, 0.83, 0.60)
)
```

Laying out the data by column can make it hard to see how the rows are related, so an alternative is `tribble()`, short for **tr**ansposed t**ibble**, which lets you lay out your data row by row.
`tribble()` is customized for data entry in code: column headings start with `~` and entries are separated by commas.
This makes it possible to lay out small amounts of data in an easy to read form:

```{r}
tribble(
  ~x, ~y, ~z,
  1, "h", 0.08,
  2, "m", 0.83,
  5, "g", 0.60
)
```

## Summary

In this chapter, you've learned how to load CSV files with `read_csv()` and to do your own data entry with `tibble()` and `tribble()`.
You've learned how csv files work, some of the problems you might encounter, and how to overcome them.
We'll come to data import a few times in this book: @sec-import-spreadsheets from Excel and Google Sheets, @sec-import-databases will show you how to load data from databases, @sec-arrow from parquet files, @sec-rectangling from JSON, and @sec-scraping from websites.

We're just about at the end of this section of the book, but there's one important last topic to cover: how to get help.
So in the next chapter, you'll learn some good places to look for help, how to create a reprex to maximize your chances of getting good help, and some general advice on keeping up with the world of R.
