# まえがき {#sec-intro .unnumbered}

```{r}
#| echo: false

source("_common.R")
```

データサイエンスは、生のデータを理解、洞察、知識へと変換できる、わくわくする学科です。
"Rではじめるデータサイエンス"のゴールは、あなたがデータサイエンスを効率的に、再現可能な格好で、そしてその過程を楽しめる😃 よう、Rの最も重要な道具を学習することを助けることです。
本書の読後には、Rの最良な部分を使って、データサイエンスの多種多様の挑戦に取り組むための道具を身に付けていることでしょう。

## 何を学ぶのか

データサイエンスは広大な領域であり、一冊の本を読んだだけでその全てが修得できるわけがありません。
本書が狙っているのは、必要となればもっと学べる資源を読者が見つけられるよう、最も重要な道具と十分な知識の堅牢な土台を与えることです。
典型的なデータサイエンスのプロジェクトは、以下のように複数の段階から成るモデルで表せます @fig-ds-diagram 。

```{r}
#| label: fig-ds-diagram
#| echo: false
#| fig-cap: |
#|   In our model of the data science process, you start with data import
#|   and tidying. Next, you understand your data with an iterative cycle of
#|   transforming, visualizing, and modeling. You finish the process 
#|   by communicating your results to other humans.
#| fig-alt: |
#|   A diagram displaying the data science cycle: Import -> Tidy -> Understand 
#|   (which has the phases Transform -> Visualize -> Model in a cycle) -> 
#|   Communicate. Surrounding all of these is Communicate.
#| out.width: NULL

knitr::include_graphics("diagrams/data-science/base.png", dpi = 270)
```

最初に、自分が持っているデータをRに**インポート**する必要があります。
典型的には、ファイル、データベース、もしくは、ウェブに保存されているデータをアプリケーション・プログラミング・インターフェース (API) を通じて取り出し、Rにデータフレームとして持ち込む、ということです。
Rにデータをインポートしなければ、それについてデータサイエンスすることなどできません！

ひとたびデータをインポートしたなら、それを**整理**するのは良い考えです。
データを整理するとは、データセットの持つ意味と保存方法が一致するよう、首尾一貫した様式で保存することです。
簡単に言えば、データが整理されていれば、各列は変数に、各行は観測値になっています。
整理されたデータが重要なのは、その首尾一貫した構造のおかげで、異なる関数ごとに正しい様式にしようとデータと格闘することなく、データについての質問に答えることに努力を集中できるからです。

ひとたびデータを整理すれば、次のステップは普通それを**変換**することです。
変換とは、（一つの都市の全員とか、昨年の全てのデータとか）興味のある観測値に絞り込む、（距離と時間から速度を計算するなど）既存の変数から関数を使って新しい変数を作り出す、（カウントや平均など）一連の要約統計値を計算する、などのことです。
整理と変換を合わせて**手懐け**と呼びます。と
いうのも、データを仕事を進めるのに自然な様式にすることは、動物を手懐けるに等しい闘いに感じられるのがしばしばだからです！

ひとたび必要な変数を含む整理されたデータを得れば、知識を創造する主に二つのエンジンが使えます。可
視化とモデルです。
これらの強みと弱みは補完関係にあるので、実際のデータ分析ではこれらの間を何度も行ったり来たりすることになります。

**可視化**は根本的に人向けの活動です。
良い可視化では、予想していなかった物事が見えたり、データについて新しい質問を思い付いたりします。
さらに、間違った質問をしていたとか、異なるデータを集める必要があるとか、気付かされるかもしれません。
可視化はあなたを驚かせることができますが、人が見て解釈しないといけないので、観測値がとても多いとあまり上手く行きません。

**モデル**は可視化を補完する道具です。
ひとたび十分に精密な質問を持ったなら、モデルを使って答えることができます。
モデルは根本的に数学的、あるいは、計算上の道具なので、観測値が多くなっても一般的には上手く行きます。
上手く行かないときでも、追加で頭脳を買うよりもコンピューターを買った方が通常安上がりです！
ただし、全てのモデルには前提が置かれています。そ
の性質ゆえ、モデルは自身の前提を疑えません。
モデルはあなたを驚かせることが根本的にできない、ということです。

データサイエンスの最後のステップは**コミュニケーション**で、どんなデータ分析プロジェクトでも絶対的に大事な部分です。
どれだけモデルや可視化を通してデータを理解できたとしても、あなたの得た結果を他者に伝えることができなければ、何の意味もありません。

これら全ての道具を取り囲んでいるのが**プログラム**です。
プログラムは、データサイエンスのプロジェクトのほぼ全ての部分で使う分野横断的な道具です。
データサイエンティストとして成功するのに、プロのプログラマーになる必要はありませんが、より良いプログラマーになれば、よくある業務を自動化したり、新しい問題をより容易に解けたりできるので、プログラムについてさらに学習することは割の良い投資です。

本書で学ぶ道具は、データサイエンスの全てのプロジェクトで使うことになりますが、ほとんどのプロジェクトではそれだけでは足りません。
大まかに 80/20 ルールが働いています。本
書で学ぶ道具を使って全てのプロジェクトの約80％はこなせますが、残りの20％に取り組むには他の道具が必要になります。
本書を通じて、さらに学習できる資源を指し示すことにします。

## 本書の構成

データサイエンスの道具について、ここまでは、大まかに分析で使う順（と言っても、当然何度も行ったり来たりするのですが）に描写してきました。
しかし、最初にデータのインポートと整理を学習するのは、経験上、最適ではありません。と
いうのも、80％の時間は決まりきった作業で退屈、残り20％の時間は訳のわからない作業で不満がたまるからです。
新しい主題を学びはじめる場所としてふさわしくない！
替わりに、インポートと整理が済んだデータの可視化と変換からはじめます。こ
うすることで、いざ自分のデータをインポートして整理する際に、動機を高く保てます。苦
痛が努力に見合うものだと知っているからです。

各章内で、首尾一貫したパターンに固執するよう努めました。動
機付けになる例でより大きな絵が見えるようにはじめて、それから詳細に潜っていきます。
本書の各セクションには、学んだばかりのことを練習できるよう演習を置きました。
演習はスキップしたくなるかもしれませんが、実際の問題で練習することよりも優れた方法はありません。

## 何を学ばないか

本書がカバーしていない重要トピックはいくつもあります。
あなたが可能な限り素早く立ち上がって走って行けるよう、本質的なことだけに無慈悲なほどにフォーカスし続けることが重要だと信じています。
本書で全ての重要トピックをカバーすることはできない、ということです。

### モデル

モデルはデータサイエンスにとってとても重要ですが、大きなトピックでもあり、残念ながら、それに見合う扱いでカバーするには本書にはスペースが足りません。
モデルについてさらに学ぶには、われわれの同僚のMax Kuhn と Julia Silgeによる著作 [Tidy Modeling with R](https://www.tmwr.org) をお薦めします。
tidymodels パッケージ（その名から推測できるように、本書で使用する tidyverse パッケージと多くの慣行を共有しています）を教えてくれます。

### ビッグデータ

本書は、主にメモリーに置ける程度の小さいデータセットに、誇りを持ってフォーカスしています。
小さいデータの経験がなければ、ビッグデータに取り組むことなどできないのですから、小さいデータからはじめるのが正しい。
本書の大部分を通して学ぶ道具は、数百メガバイトのデータを容易に扱えますし、数ギガバイトのデータでも、少々注意すれば、典型的には扱えます。
また、ビッグデータを保存するのに多く用いられているデータベースや parquet ファイルからデータを取り出すやり方も示します。
データセットの全体で作業する必要は必ずしもないのです。興
味を持った質問に答えるのに必要なのはサブセットやサブサンプルだけなので、全体を扱えないことは問題ではないのです。

（例えば、10--100 GBの）より大きなデータでいつも作業しているなら、[data.table](https://github.com/Rdatatable/data.table)についてさらに学習することを薦めます。
本書で教えていないのは、tidyverse とインターフェースが異なり、いくつか別の慣行を学ばなければならないからです。
しかし、その速さは驚くべきもので、大きなデータを扱っているなら、時間を割いて学習することは割に合います。

### Python、Julia、その他の言語

PythonやJulia、その他データサイエンスに役立つプログラム言語について、本書では全く学びません。
それらの道具が不出来だと考えたからではありません。
不出来などではありません！
実際のところ、ほとんどのデータサイエンス・チームは複数の言語、多くの場合少なくともRとPythonを、組み合わせて使っています。
けれども、いっときに修得するには一つの道具に絞るのが最良であり、Rからはじめるのが良いとわれわれは強く信じているのです。

## 準備するもの

本書から最大限学んでもらうために、読者が既知であることについて、いくつか前提を置いています。
読者は総じて数値の扱いに長けていること。既
に基礎的なプログラムの経験があれば、助けになります。
これまで一度もプログラムをしたことがないなら、Garrettの著作 [Hands on Programming with R](https://rstudio-education.github.io/hopr/) が本書にとって価値ある副読本になるかもしれません。

本書中のコードを走らせるには４つのものが必要です。R
、RStudio、**tidyverse**と呼ばれるRパッケージ群、そしていくつかのその他パッケージです。
パッケージは再現可能なRコードの基礎を成すものです。
パッケージは、再利用可能な関数、それらの使い方を記したドキュメント、そしてサンプル・データを含んでいます。

### R

Rをダウンロードするには、CRAN, the **c**omprehensive **R** **a**rchive **n**etwork, <https://cloud.r-project.org>に行きます。
Rの主要バージョンは年１回のペースで出て来ますが、年に２、３回のペースでマイナー・バージョンもリリースされます。
定期的な更新をお薦めします。
更新は少々手間がかかることがあります。特
に主要バージョンへの更新では全てのパッケージを再インストールする必要があります。し
かし、更新を先延ばしていては、事態は悪くなる一方です。
R 4.2.0以上のバージョンを本書ではお薦めします。

### RStudio

RStudioはRプログラム向けの統合開発環境、IDEで、<https://posit.co/download/rstudio-desktop/>からダウンロードできます。
年に２、３回アップデートされ、新しいバージョンが出れば自動的に知らせますので、チェックする必要はありません。
定期的に更新して、最新かつ最強の機能を利用することをお薦めします。
本書では、RStudio 2022.02.0以上のバージョンを使うようにしてください。

RStudioを起動すると @fig-rstudio-console、画面に２つの領域が現れます。コンソール区画と出力区画です。
今のところは、Rコードをコンソール区画に打ち込んで、Enterを押せば実行されると知っていれば十分です。
先に進むに連れて使い方をもっと学んでいきます！[^intro-1]

[^intro-1]: RStudioの全機能を網羅的に知りたいのなら、<https://docs.posit.co/ide/user>にあるユーザー・ガイドにあたってください。

```{r}
#| label: fig-rstudio-console
#| echo: false
#| out-width: ~
#| fig-cap: |
#|   The RStudio IDE has two key regions: type R code in the console pane
#|   on the left, and look for plots in the output pane on the right.
#| fig-alt: |
#|   The RStudio IDE with the panes Console and Output highlighted.
knitr::include_graphics("diagrams/rstudio/console.png", dpi = 270)
```

### tidyverse

他にもいくつかRパッケージをインストールするひつようがあります。
R**パッケージ**は関数、データ、ドキュメントの集合で、ベースRの機能を拡張します。
パッケージの利用がRを上手く使いこなす鍵です。
本書で学ぶパッケージの大半はいわゆるtidyverseに属しています。
tidyverseに属する全てのパッケージはデータとRプログラムについて同じ哲学を共有しており、手を携えて働くよう設計されています。
tidyverseのコアに当たるパッケージ群は以下の一行コードでインストールできます。

```{r}
#| eval: false

install.packages("tidyverse")
```

あなたのコンピューターで、コンソール区画にこのコードを打ち込んで、Enterを押すと、走り出します。
RがCRANからパッケージをダウンロードして、あなたのコンピューターにインストールします。

そのままではパッケージ内の関数、オブジェクト、ヘルプ・ファイルは使えません。`l`
`ibrary()`でロードしてはじめて使えるようになります。
パッケージのインストールが済んでいれば、以下のように`library()`関数を使えばロードできます。

```{r}
library(tidyverse)
```

dplyr、forcats、ggplot2、lubridate、purrr、readr、stringr、tibble、tidyrの9つのパッケージがロードされたことが分かります。
これら9つのパッケージは、ほとんど全ての分析で使うので、tidyverseの**コア**と考えられています。

tidyverse中のパッケージはかなり頻繁にアップデートされます。
`tidyverse_update()`を実行すると、入手可能なアップデートがあるか知ることができます。

### その他のパッケージ

tidyverseに属さないその他の優れたパッケージも数多くあり、tidyverseとは違った領域で問題を解いたり、違った通底に流れる原理原則の基に設計されていたりします。
だからといって、これらその他パッケージがtidyverseよりも良いとか悪いとかというわけではありません。た
だ違っているだけです。
言い換えると、tidyverse（整理された世界）を補完するのは、messyverse（乱雑な世界）ではなく、お互いに関連するパッケージの数多くの世界なのです。
Rを使ってデータサイエンスのプロジェクトにさらに取り組みにつれて、新しいパッケージやデータについての新しい考え方を学んでいきます。

本書ではtidyverse以外の多くのパッケージを使います。
例えば、Rを学習する過程で興味深いデータセットを与えてくれたりするので、以下のパッケージを使います。

```{r}
#| eval: false

install.packages(
  c("arrow", "babynames", "curl", "duckdb", "gapminder", 
    "ggrepel", "ggridges", "ggthemes", "hexbin", "janitor", "Lahman", 
    "leaflet", "maps", "nycflights13", "openxlsx", "palmerpenguins", 
    "repurrrsive", "tidymodels", "writexl")
  )
```

これら以外にも、その場限りの例で用いるパッケージがあります。
今はインストールする必要はありませんが、以下のようなエラーを見たときは、そのことを思い出してください。

```{r}
#| eval: false

library(ggrepel)
#> Error in library(ggrepel) : there is no package called ‘ggrepel’
```

その際は、`install.packages("ggrepel")`を実行して、パッケージをインストールします。

## Rコードの実行

ここまでにRコードを実行する例をいくつか示してきました。
本書でのコードは以下のように表示します。

```{r}
#| eval: true
1 + 2
```

同じコードをあなたのコンピューターのコンソールで実行するすると、以下のように表示されます。

```         
> 1 + 2
[1] 3
```

２つ大きな違いがあります。
あなたのコンソールでは、**プロンプト**と呼ばれる`>`の後に打ち込みますが、本書ではプロンプトは表示しません。
出力は、本書では`#>`でコメント・アウトしていますが、あなたのコンソールでは打ち込んだコードの直後に出て来ます。
この２つの大きな違いのおかげで、本書の電子版を使っているなら、本書のコードをコピーして、あなたのコンソールにペーストするのが容易になっています。

本書を通して、コードを示すのに、以下のように首尾一貫した複数の慣行に従います。

-   関数はコード・フォントで、最後に()を付けます。`s`
    `um()`とか`mean()`とかのように表記します。

-   その他のRオブジェクト（データや関数の引数など）はコード・フォントで、()は付けません。`f`
    `lights`とか`x`とかのように表記します。

-   ときには、そのオブジェクトがどのパッケージから来たものかはっきりさせるために、パッケージ名の後ろに２つコロンを付けて、例えば、`dplyr::mutate()`や`nycflights13::flights`のようにします。
    これもまた有効なRコードです。

## 謝辞

本書がHadley、Mine、Garrettだけの生産物ではなく、Rコミュニティの多くの人たちとの（面と向かった、あるいは、オンラインでの）数多くの会話の結果です。
みんなとの全ての会話を信じられないほど感謝しています。
ありがとう。

```{r}
#| eval: false
#| echo: false

library(tidyverse)
contribs_all_json <- gh::gh("/repos/:owner/:repo/contributors",
  owner = "hadley",
  repo = "r4ds",
  .limit = Inf
)
contribs_all <- tibble(
  login = contribs_all_json |> map_chr("login"),
  n = contribs_all_json |> map_int("contributions")
)

contribs_old <- read_csv("contributors.csv", col_types = list())
contribs_new <- contribs_all |> anti_join(contribs_old, by = "login")

# Get info for new contributors
needed_json <- map(
  contribs_new$login, 
  ~ gh::gh("/users/:username", username = .x),
  .progress = TRUE
)
info_new <- tibble(
  login = contribs_new$login,
  name = map_chr(needed_json, "name", .default = NA),
  blog = map_chr(needed_json, "blog", .default = NA)
)
info_old <- contribs_old |> select(login, name, blog)
info_all <- bind_rows(info_old, info_new)

contribs_all <- contribs_all |> 
  left_join(info_all, by = "login") |> 
  mutate(login_lowercase = str_to_lower(login)) |>
  arrange(login_lowercase) |>
  select(-login_lowercase)
write_csv(contribs_all, "contributors.csv")
```

```{r}
#| results: asis
#| echo: false
#| message: false

library(dplyr)
contributors <- readr::read_csv("contributors.csv")
contributors <- contributors |> 
  filter(!login %in% c("hadley", "garrettgman", "mine-cetinkaya-rundel")) |> 
  mutate(
    login = paste0("\\@", login),
    desc = ifelse(is.na(name), login, paste0(name, " (", login, ")"))
  )

cat("This book was written in the open, and many people contributed via pull requests. A special thanks to all ",nrow(contributors), " of you who contributed improvements via GitHub pull requests (in alphabetical order by username): ", sep = "")
cat(paste0(contributors$desc, collapse = ", "))
cat(".\n")
```

## 奥付

本書のオンライン版は <https://r4ds.hadley.nz>にあります。
オンライン版は、紙の本が再刷される間にも、進化し続けます。
本書のソースコードは <https://github.com/hadley/r4ds>にあります。
本書のエンジンは [Quarto](https://quarto.org)です。お
かげで、文章と実行可能なコードを組み合わせて本を書くことが簡単になりました。

```{r}
#| eval: false
#| echo: false
#| results: asis

pkgs <- sessioninfo::package_info(
  tidyverse:::tidyverse_packages(),
  dependencies = FALSE
)
df <- tibble(
  package = pkgs$package,
  version = pkgs$ondiskversion,
  source = gsub("@", "\\\\@", pkgs$source)
)
knitr::kable(df, format = "markdown")
```

```{r}
#| include: false

cli:::ruler()
```
