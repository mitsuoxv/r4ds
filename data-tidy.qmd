# データ整理 {#sec-data-tidy}

```{r}
#| echo: false

source("_common.R")
```

## はじめに

> "幸福な家庭は皆似ているが、不幸な家庭は皆それぞれ異なる仕方で不幸なのだ。"\
> --- Leo Tolstoy

> "整理データセットは皆似ているが、未整理データセットは皆それぞれ異なる仕方で未整理なのだ。"\
> --- Hadley Wickham

本章では、**整理データ**と呼ばれるシステムを使って、Rでデータを整頓する首尾一貫した方法を学びます。
データをその形式にするには、最初にいくつか仕事が必要です。し
かし、長い目で見ると、この仕事は割に合います。
整理データとtidyverseのパッケージ群が提供する整理された道具をひとたび入手すれば、データをある表現から別の表現に変えるのにかける時間を節約して、気になるデータについての質問に時間をかけることができます。

本章では、最初に整理データの定義を学習して、簡単な学習用データセットに適用してみます。
それから、データを整理するのに使う主要な道具であるピボット (旋回) に入っていきます。
ピボットを使うと、値を変えることなく、データの形式を変えられます。

### 準備するもの

本章では、tidyrパッケージにフォーカスします。未
整理データセットを整理する助けになる道具を提供してくれます。
tidyrはtidyverseのコア・メンバーです。

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

本章以降、`library(tidyverse)`から出力されるメッセージは表示しないことにします。

## 整理データ {#sec-tidy-data}

同じデータを複数の方法で表現することができます。
以下の例は、同じデータを3つの異なる方法で整頓しています。
どのデータセットでも、4つの変数*country*、*year*、*population*、TB (結核) の記録された件数である*cases*の値は同じですが、それぞれ異なる仕方で値を整頓しています。

```{r}
table1

table2

table3
```

これらは全て、同じデータを表現したものですが、使いやすさは同じではありません。
その一つ、`table1`はtidyverse内部で処理するのがずっと簡単です。
**整理データ**だからです。

整理データセットであるための、相互に関連する3条件は、

1.  各変数は1つの列であり、各列は1つの変数である。
2.  各観測は1つの行であり、各行は1つの観測である。
3.  各値は1つのセルであり、各セルは1つの値である。

@fig-tidy-structure で、3条件を可視化しています。

```{r}
#| label: fig-tidy-structure
#| echo: false
#| fig-cap: | 
#|   データセットが整理データであるための3条件。
#|   変数は列、観測は行、値はセル。
#| fig-alt: | 
#|   整理データフレームを表現した3つのパネル。
#|   第1のパネルは、各変数は1つの列を示す。
#|   第2のパネルは、各観測は1つの行を示す。
#|   第3のパネルは、各値は1つのセルを示す。

knitr::include_graphics("images/tidy-1.png", dpi = 270)
```

整理データにしておく理由は何でしょう？
大きな利点が2つあります。

1.  データを保存する首尾一貫した方法を一つ採用することは、一般的に利点になります。
    首尾一貫したデータ構造であれば、その根底にある一様さのおかげで、それと一緒に働く道具を学習するのが容易になります。

2.  変数を列に置くことは、Rのベクトル化仕様を輝かせられるので、特に利点となります。
    @sec-mutate と @sec-summarize で学習したように、ほとんどのRの組み込み関数はベクトル化された値で機能します。
    そのおかげで、整理データの変換は特に自然になります。

tidyverseのdplyr、ggplot2やその他全てのパッケージは整理データで機能するよう設計されています。
以下は、`table1`を使った2、3の小さな例です。

```{r}
#| fig-width: 5
#| fig-alt: |
#|   アフガニスタン、ブラジル、中国の1999年と2000年のケース数のプロット。
#|   x軸に年、y軸にケース数としている。プロットの各点は各国の各年の
#|   ケース数を表している。国ごとに点の色と形を変え、線で結んでおり、
#|   並行でも交わってもいない3本の線になっている。
#|   1999年と2000年の両年とも中国がケース数が200,000超と最多。
#|   ブラジルのケース数は1999年に約40,000、2000年に約75,000。
#|   アフガニスタンのケース数は1999年と2000年の両年とも最小で、
#|   この尺度では0にとても近く見える。

# 10,000人当たりのケース数を計算
table1 |>
  mutate(rate = cases / population * 10000)

# 年ごとの総ケース数を計算
table1 |> 
  group_by(year) |> 
  summarize(total_cases = sum(cases))

# 経年変化を可視化
ggplot(table1, aes(x = year, y = cases)) +
  geom_line(aes(group = country), color = "grey50") +
  geom_point(aes(color = country, shape = country)) +
  scale_x_continuous(breaks = c(1999, 2000)) # x-axis breaks at 1999 and 2000
```

### 練習問題

1.  サンプル・テーブルごとに、各観測と各列が何を表しているか述べなさい。

2.  `table2`と`table3`で、10,000人当たりのケース数`rate`を計算する過程を描きなさい。
    以下4つの操作が必要になります。

    a.  各国各年の結核ケース数を取り出す。
    b.  各国各年が一致する人口を取り出す。
    c.  ケース数を人口で割り、10000を掛ける。
    d.  適当な場所に保存し戻す。

    これらの操作を実際に行うのに必要な関数の全てをまだ学習していません。
    それでも、必要な変換を考え通すことはできるはずです。

## データを縦長に {#sec-pivoting}

整理データの原則はあまりに当たり前なので、未整理のデータセットに出会うことがあるのだろうか、と思うかもしれません。
でも、残念なことに、ほとんどの実地のデータは未整理です。
その理由は2つあります。

1.  データを分析以外のある目標を容易するよう整頓されていることがよくあります。
    たとえば、データの分析ではなく、入力を容易にするようデータが構造化されているのは、よくあることです。

2.  ほとんどの人は整理データの原則に馴染みがないので、データを使う仕事に多くの時間を費やすのでなければ、整理データの原則を自分で導き出すことは困難です。

つまり、実地に分析する際は、ほとんどの場合、少なくとも少々データ整理が必要だということです。
根底にある変数と観測が何か、見い出すことからはじめます。
簡単にできることもありますが、そうでないときは、元々データを生成した人に相談する必要があります。
次に、データをピボットして、列に変数、行に観測という整理された形式にします。

データをピボットするのに、tidyrは`pivot_longer()`と`pivot_wider()`の2つの関数を提供してくれます。
最も普通に使う`pivot_longer()`から学習します。
いくつかの例から入っていきましょう。

### 列名がデータである場合 {#sec-billboard}

`billboard`データセットは、2000年の各曲のビルボード・ランキングを記録しています。

```{r}
billboard
```

このデータセットでは、各観測は1つの曲です。
最初の3列 (`artist`、`track`、`date.entered`) は曲を記述する変数です。
その先に76列 (`wk1`-`wk76`) あって、各週の順位を表しています[^data-tidy-1]。
これらの列名は1つの変数 (the `week`) で、セルの値は別の変数 (the `rank`) です。

[^data-tidy-1]: 2000年のどこかの時点でトップ100に入った曲が含まれており、最初に現れてから最大76週間追跡されている。

このデータを整理するには、`pivot_longer()`を使います。

```{r, R.options=list(pillar.print_min = 10)}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```

第1引数のデータの後に、鍵となる3つの引数があります。

-   `cols`は、ピボットする必要のある列、つまりは変数ではない列、を指定します。この引数は`select()`と同じ文法を使うので、ここでは`!c(artist, track, date.entered)`とか`starts_with("wk")`のようにできます。
-   `names_to`は、列名が入る変数に名前を付けます。ここでは`week`と名付けました。
-   `values_to`は、セルの値が入る変数に名前を付けます。ここでは`rank`と名付けました。

`"week"`と`"rank"`には引用符が付いていることに注意してください。こ
れらは、これから作成しようとしている新変数で、`pivot_longer()`を呼び出した時点ではまだデータに存在しないからです。

では、結果として縦長になったデータフレームに目を向けましょう。
トップ100に76週未満しか入っていなかった曲はどうなっているでしょうか？
例えば、2 Pacの"Baby Don't Cry"を見てみましょう。
上記の出力では、トップ100には7週間だけ入っていましたが、残りの週は全て欠損値となっています。
これらの`NA`は、実際は、未知の観測を表すものではなく、データセットの構造上無理に存在させられていたものです[^data-tidy-2]。
ですから、`pivot_longer()`で`values_drop_na = TRUE`と設定することで、除去できます。

[^data-tidy-2]: この考え方については @sec-missing-values で立ち戻ります。

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

行数はずいぶん減りました。多
くあった`NA`だった行が除去されたということです。

76週超トップ100に入っていた曲はどうするのか、と思うかもしれません。
このデータからは何とも言えませんが、データセットに`wk77`、`wk78`、...と列を追加することになるのかな。

これで整理データになっていますが、先の計算を少しばかり容易にするため、`mutate()`と`readr::parse_number()`を使って、`week`の値を文字列から数値に変換します。
`parse_number()`は、文字列内の数値以外の文字は無視して、最初の数値を取り出すお手軽な関数です。

```{r}
billboard_longer <- billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  ) |> 
  mutate(
    week = parse_number(week)
  )
billboard_longer
```

これで、週数を全て一つの変数に、順位を全てもう一つの変数にできました。順
位が時を経るにつれてどう変化するか可視化する準備ができました。
コードは以下、結果は @fig-billboard-ranks です。
20週超トップ100にとどまる曲はごくわずかだと分かります。

```{r}
#| label: fig-billboard-ranks
#| fig-cap: |
#|   曲の順位が経時的にどう変化するかを示す線グラフ
#| fig-alt: |
#|   x軸がweek、y軸がrankの線グラフ。
#|   各線が各曲を表す。ほとんどの曲は高い順位で現れ、
#|   急速に順位を落とし、消えていく。
#|   weekが20超、rankが50以上の領域に入る曲は驚くほど少ない。

billboard_longer |> 
  ggplot(aes(x = week, y = rank, group = track)) + 
  geom_line(alpha = 0.25) + 
  scale_y_reverse()
```

### ピボットはどう機能するのか？

データを変形するのにピボットがどう使えるのか見てきましたので、次に少し時間を取って、ピボットがデータに何をしているのか、直観を養いましょう。
とても単純なデータセットからはじめて、何が起きているのか見やすくしましょう。
`id`がA、B、Cの3人の患者がいて、患者ごとに2回血圧測定するとします。
小さなtibbleを手書きで作る手軽な関数`tribble()`を使って、データを作ります。

```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)
```

欲しいのは、`id` (これは既にあります) 、`measurement` (列名) 、`value` (セルの値) の3つの変数を持つ新しいデータセットです。
そうするには、`df`をピボットして長くする必要があります。

```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
```

変形はどう機能していますか？
列ごとに考えると見やすくなります。
@fig-pivot-variables に示したように、元のデータセットに既にあった変数 (`id`) の列にあった値は、ピボットされる列の数だけ繰り返されています。

```{r}
#| label: fig-pivot-variables
#| echo: false
#| fig-cap: | 
#|   既に変数だった列は、ピボットされる列の数だけ繰り返される。
#| fig-alt: | 
#|   `pivot_longer()`が単純なデータセットを変形する仕方を示すダイアグラム。
#|   出力では、`id`列の値 ("A"、"B"、"C") がそれぞれ2回繰り返されている
#|   ことを色を使ってハイライト。繰り返しが2回なのは、ピボットされる
#|   列 ("bp1"、"bp2") が2つだから。

knitr::include_graphics("diagrams/tidy-data/variables.png", dpi = 270)
```

@fig-pivot-names に示すように、列名は新変数の値になり、新変数の名前は`names_to`で指定した名前になります。
列名だった値は元のデータセットの行数回だけ繰り返されます。

```{r}
#| label: fig-pivot-names
#| echo: false
#| fig-cap: |
#|   ピボットされた列の列名は新しく出来る列の値になる。
#|   それらの値は元のデータセットの行数回繰り返される必要がある。
#| fig-alt: | 
#|   `pivot_longer()`が単純なデータセットを変形する仕方を示すダイアグラム。
#|   出力では、列名 ("bp1"、"bp2") が新しく出来る`measurement`列の
#|   値になることを色を使ってハイライト。
#|   それらが3回繰り返されているのは、入力が3行だったから。

knitr::include_graphics("diagrams/tidy-data/column-names.png", dpi = 270)
```

セル値も、`values_to`で名前を指定した新変数の値になります。
行ごとに展開されます。
@fig-pivot-values でその過程を示します。

```{r}
#| label: fig-pivot-values
#| echo: false
#| fig-cap: |
#|   値の数は維持される (繰り返されることはない) が、
#|   行ごとに展開される。
#| fig-alt: | 
#|   `pivot_longer()`が単純なデータセットを変形する仕方を示すダイアグラム。
#|   出力では、セル値 (血圧測定値) が新しく出来る`value`列の
#|   値になることを色を使ってハイライト。
#|   セル値は行ごとに展開される。
#|   だから、元の最初の行 (100,120)、次の行 (140,115)、その次の行 (120,125)の
#|   順に100から125までの列になる。

knitr::include_graphics("diagrams/tidy-data/cell-values.png", dpi = 270)
```

### 列名に多数の変数が入っている場合

列名に複数の情報が詰め込まれて、それぞれ別々の新変数に入れたい場合、より挑戦的な状況になります。
例えば、上で見た`table1`とその仲間たちの出所である`who2`を見てみましょう。

```{r}
who2
```

この世界保健機関が収集したデータセットは、結核診断数について情報を記録しています。
既に変数になっており、解釈が容易な列が、`country`と`year`の2つあります。
その先には56列あり、`sp_m_014`、`ep_m_4554`、`rel_m_3544`などの列名です。
これらの列名を十分長い時間見つめていると、パターンに気付きます。
各列名は、`_`で区切られた3つの情報から出来ています。
1つ目は`sp`/`rel`/`ep`で診断方法を、2つ目は`m`/`f`で`gender` (このデータセットでは男女2区分コードの性別) を、3つ目は`014`/`1524`/`2534`/`3544`/`4554`/`5564`/`65`で`age` (年齢層。例えば、`014`は0-14のこと) を表す。

ですから、この場合、`who2`に記録されている情報は6つあることになります。(
既に列になっている) 国、年と、(残りの列名に含まれている) 診断方法、性別カテゴリ、年齢層カテゴリと、(セル値である) 各カテゴリごとの患者数の6つです。
これら6つの情報を6つの別々の列に整頓するには、`pivot_longer()`で`names_to`に列名ベクトルを指定、`names_sep`で元の変数名を分割する方法を指示、そして`values_to`にセル値を入れる列名を指定します。

```{r}
who2 |> 
  pivot_longer(
    cols = !(country:year),
    names_to = c("diagnosis", "gender", "age"), 
    names_sep = "_",
    values_to = "count"
  )
```

@sec-regular-expressions で正規表現を学習すれば、より複雑な名付け方法であっても変数を取り出せる`names_pattern`を、`names_sep`の替わりに使えるようになります。

概念的には、これまでに見てきたより単純なケースから、ほんの少しだけ違っているだけです。
@fig-pivot-multiple-names では、基本的な考え方を示しています。こ
こでは、 列名が1つの列にピボットするのではなく、複数の列にピボットします。
(まずピボットして、次に分ける) 2ステップで処理していると想像できますが、内部ではその方が速いので1ステップで処理しています。

```{r}
#| label: fig-pivot-multiple-names
#| echo: false
#| fig-cap: |
#|   列名に複数の情報を含む列のピボット。
#|   出力では、複数の情報は、複数のそれぞれの列で値となる。
#| fig-alt: |
#|   `names_sep`を指定、`names_to`に複数の列名を与えて、
#|   出力では複数の変数を作るのを、色を使ってハイライトしたダイアグラム。
#|   入力には"x_1"と"y_2"の変数名があり、"_"で切り分けることで、
#|   出力では"name"と"number"の列を作る。
#|   `names_to`に1つの列名を与えるケースと似ているが、
#|   出力では1つの変数だったものが、ここでは複数の変数に分かれている。

knitr::include_graphics("diagrams/tidy-data/multiple-names.png", dpi = 270)
```

### 列名に変数名とデータが入っている場合

もう一段複雑さが増すのは、列名が変数名と別変数の値のミックスになっている場合です。
例えば、`household`データセットを見てみましょう。

```{r}
household
```

このデータセットには5つの家庭のデータがあり、家庭ごとに2人までの子どもの名前と誕生日が入っています。
このデータセットで新たな挑戦となるのは、列名に2つの変数名 (`dob`と`name)` と、もう一つ変数の値 (`child`が1か2) が入っていることです。
この問題を解くには、また`names_to`に列名ベクトルを指定する必要がありますが、ここでは特殊な列名`".value"`を使います。こ
れは変数名ではなく、`pivot_longer()`に違った動作をしてもらうために指定する特殊な値です。
いつもは`values_to`引数で値が入る変数名を指定しますが、以下のようにするとピボットされた列名の最初の構成要素が値が入る変数名になります。

```{r}
household |> 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

ここでも`values_drop_na = TRUE`として、元のデータセットの形のせいで強制的に作られていた明示的欠損値 (例えば、子どもが1人の家庭での2人目のセル) を除去しています。

@fig-pivot-names-and-values はより簡単な例で基本的な考え方を示しています。
`names_to`の中で`".value"`を使うと、入力の列名は出力の値と変数名の両方に分かれて入ります。

```{r}
#| label: fig-pivot-names-and-values
#| echo: false
#| fig-cap: |
#|   `names_to = c(".value", "num")`としてピボットすると、列名は2つの
#|   構成要素に分割される。第1の構成要素が出力での列名 (`x`と`y`) を
#|   決め、第2の構成要素が`num`列の値となる。
#| fig-alt: |
#|   特殊な列名".value"の指定がどう機能するかを色を使って表したダイアグラム。
#|   ピボットで入力する列名は"x_1"、"x_2"、"y_1"、"y_2"で、第1の構成要素
#|   ("x"と"y") を変数名に、第2の構成要素 ("1"と"2") は新しい列"num"の値に
#|   使いたい。

knitr::include_graphics("diagrams/tidy-data/names-and-values.png", dpi = 270)
```

## データを幅広に

ここまでは`pivot_longer()`を使って、列名に値が入ってしまっている、というよくあるタイプの問題を解いてきました。
次に、`pivot_wider()`にピボット (笑) しましょう。`p`
`ivot_wider()`は列数を増やし行数を減らすことで、データセットを**幅広に**します。一
つの観測が複数列にわたる場合、助けになります。
そこいらではあまりお目にかからないかもしれませんが、政府データを処理する場合はよくあることのように思われます。

米国保健福祉省のメディケア・メディケイド・サービスセンターが収集した患者体験についてのデータセット`cms_patient_experience`を見ることからはじめます。

```{r}
cms_patient_experience
```

調査対象のコア単位は組織ですが、組織ごとに6行あって、その組織で取られたアンケート結果が各行になっています。
`distinct()`を使って、`measure_cd`と`measure_title`の値の完全なセットを見ることができます。

```{r}
cms_patient_experience |> 
  distinct(measure_cd, measure_title)
```

これらの列はどちらも特に優れた変数名になりそうもありません。
`measure_cd`の6つの値は、意味のヒントになる変数名になりませんし、`measure_title`の6つの値はそれぞれスペースを含む長い文章です。
ここでは`measure_cd`を新しい列名の源として使いますが、実際に分析する際は、短くて意味のある変数名を自分で作りたくなるかもしれません。

`pivot_wider()`のインターフェースは、`pivot_longer()`の逆です。新
しい列名を選ぶのではなく、値が入っている既存の列 (`values_from`) と、変数名が入っている既存の列 (`names_from`) を指定する必要があります。

```{r}
cms_patient_experience |> 
  pivot_wider(
    names_from = measure_cd,
    values_from = prf_rate
  )
```

この出力は正しくないようです。依
然、組織ごとに複数の行があります。
単一の行をユニークに特定する1つ、または、複数のID列も、`pivot_wider()`に伝える必要がある、ということです。
このケースでは、それは組織を特定する`"org"`で始まる2つの変数です。

```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

これで、望んでいた出力になりました。

### `pivot_wider()`はどう機能するのか？

`pivot_wider()`がどう機能するのか理解するため、再びとても単純なデータセットを使ってはじめます。
患者は2人で`id`はAとB。患
者Aには3度、患者Bには2度、血圧測定したとします。

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)
```

`value`列から値を、`measurement`列から変数名を取ります。

```{r}
df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

`pivot_wider()`が処理をはじめるには、何が行と列に入るのか、まず伝える必要があります。
新しい変数名は`measurement`のユニークな値です。

```{r}
df |> 
  distinct(measurement) |> 
  pull()
```

デフォルトでは、出力での行は、新しい変数名にも値にも入らないその他全ての変数から決まります。
それを`id_cols`と呼びます。
ここでは列が1つだけですが、一般的に複数にもなりえます。

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct()
```

次に、`pivot_wider()`はこれらの結果を組み合わせて、空のデータフレームを生成します。

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
```

それから、入力のデータを使って全ての欠損値を埋めます。
このケースでは、患者Bに3度目の血圧測定値がないので、出力の全てのセルに該当する入力の値があるわけではなく、欠損値が残ります。
@sec-missing-values で、`pivot_wider()`が明示的な欠損値を作り出す、この考え方に立ち戻ります。

出力の1つのセルに該当する入力の行が複数あったらどうなるのか、とも思うかもしれません。
以下の例では、`id`が"A"で、`measurement`が"bp1"な行が2つあります。

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "A",        "bp1",    102,
  "A",        "bp2",    120,
  "B",        "bp1",    140, 
  "B",        "bp2",    115
)
```

これをピボットしようとすると、リスト型の列を含む出力を得ることになります。リ
スト型の列については、@sec-rectangling でさらに学習します。

```{r}
df |>
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

この種のデータに取り組む方法をまだ知らないので、警告の中のヒントに従って、どこに問題があるのか探り出したいとなるでしょう。

```{r}
df |> 
  group_by(id, measurement) |> 
  summarize(n = n(), .groups = "drop") |> 
  filter(n > 1)
```

データで何がまずかったのか探り出し、根底にある損害を修復するか、グループ化と要約の技能を使って行と列の各組み合わせセルに該当する行を1つだけにするか、あなた次第です。

## まとめ

本章では、列に変数を行に観測を持つデータである、整理データを学習しました。
整理データは、tidyverseのほとんどの関数が理解する首尾一貫した構造なので、作業が容易になります。受
け取ったデータの構造がどうであれ、それを整理データに変換することが主な挑戦となります。
そのために、多くの未整理データセットを整理データにできる、`pivot_longer()`と`pivot_wider()`を学習しました。
ここで示した例は、`vignette("pivot", package = "tidyr")`から選んだものです。で
すから、本章では足らない問題に出会ったら、そこを見ると良いでしょう。

もう一つの挑戦は、データセットを所与として、縦長版と幅広版のどちらが"整理データ"か、レッテルを貼れないことがあることです。
部分的には、整理データの定義のせいです。整
理データは列ごとに1つの変数を持つと言いましたが、実際には変数とは何か定義しませんでした (そうするのは驚くほど難しいのです)。
実務的になって、分析が最も容易になるよう変数を決めて、全く問題ありません。
ある計算の仕方が見出だせなくなったら、データの構成を切り替えることを検討しましょう。必
要ならば、整理を解いたり、変換したり、再度整理したり、することを恐れないでください！

本章を楽しめて、さらに根底にある理論を学習したいのなら、Journal of Statistical Softwareに掲載された論文 [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) を読めば、歴史と理論的基礎についてさらに学習できます。

ここまでで、相当な量のRコードを書いてきました。書
いたコードをファイルやディレクトリに整頓することについてさらに学習する頃合いです。
次章では、スクリプトとプロジェクトの利点と、仕事を楽にしてくれる多くの道具について学習します。
