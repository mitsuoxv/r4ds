# データ変換 {#sec-data-transform}

```{r}
#| echo: false

source("_common.R")
```

## はじめに

可視化は洞察を得るための大切な道具ですが、描きたいと思うグラフを作成するのにまさに必要な形式でデータを入手することはめったにないことです。
多くの場合、データで質問に答えるために新しい変数や要約を作る必要があります。も
しくは、データを少々扱いやすくするために変数名の変更や観察の並べ替えをしたいこともあります。
これた全て (とさらに！) を本章では学びます。
**dplyr**パッケージと新しく2013年ニューヨーク発航空便データセットを使って、データ変換を紹介します。

本章のゴールはデータフレームを変換する鍵となる道具全てをざっと示すことです。
データフレームの行を操作する関数からはじめて、次に列を操作する関数へ進みます。そ
れから振り返って、動詞を組み合わせるのに使うパイプについてさらに語ります。
次に、グループを扱うやり方を紹介します。
本章の最後は、これらの関数を実際に使う様子を示すケーススタディです。デ
ータ型 (例えば、数値、文字列、日付) ごとに掘り下げる先の章で、振り返って関数の詳細を学びます。

### 準備するもの

本章では、やはりtidyverseのコア・メンバーであるdplyrパッケージにフォーカスします。
nycflights13パッケージのデータを使って鍵となるアイディアを示します。ま
た、データを理解する助けとして、ggplot2パッケージを使います。

```{r}
#| label: setup

library(nycflights13)
library(tidyverse)
```

tidyverseをロードしたときに表示されるコンフリクト・メッセージに注意を払ってください。
dplyrがベースRのいくつかの関数を上書きしていると書いてあります。
dplyrをロード後にベースRのこれらの関数を使いたい場合は、`stats::filter()`や`stats::lag()`のように、関数のフルネームで呼ぶ必要があります。
ここまでは、関数がどのパッケージのものかほぼ無視してきました。た
いていは、どうでもよいからです。
しかし、パッケージを知っていれば、ヘルプを探したり、関連する関数を探したりする助けになります。そ
こで、関数がどのパッケージのものか精確である必要がある場合は、Rと同じ文法の`packagename::functionname()`を使うことにします。

### nycflights13

基礎的なdplyr動詞を試すため、`nycflights13::flights`を使います。
このデータセットには、2013年ニューヨーク市発の全`r format(nrow(nycflights13::flights), big.mark = ",")`飛行便が入っています。
データの出所は、[米国運輸統計局](https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr)で、ドキュメントは`?flights`で見られます。

```{r}
flights
```

`flights`は、よくある落とし穴を避けるためtidyverseが使う、特殊なタイプのデータフレームのtibbleです。
tibbleとデータフレームの最も重要な違いは、どう印刷されるかです。t
ibbleは大きなデータセット向きに設計されているので、行は最初のいくつかだけ、列は一画面に収まる分だけが表示されます。
全てを見る方法はいくつかあります。
RStudioを使っているなら、一番簡単な方法はおそらく`View(flights)`とすることです。イ
ンターアクティブ・ビューのタブが開いて、スクロールやフィルタが可能です。
他の方法としては、`print(flights, width = Inf)`とすれば全列が表示されます。あ
るいは、`glimpse()`とすれば以下のように表示されます。

```{r}
glimpse(flights)
```

どちらの表示でも、変数名の次にあるのは各変数のデータ型の略称です。`<`
`int>`は整数、`<dbl>`は倍精度浮動小数点数 (つまり実数)、`<chr>`は文字 (つまり文字列)、`<dttm>`は日付時間のことです。
変数に対して行える演算は"データ型"によって違うので、これらは大事です。

### dplyrの基本

これから学ぶのは主要なdplyr動詞 (関数) です。こ
れらを使えば、データ操作についての大抵の挑戦は解決できます。
しかし、各動詞の違いを議論する前に、共有していることを述べておいた方が良いでしょう。

1.  第1引数は、いつもデータフレーム。

2.  その次の引数は、典型的には演算対象を (引用符なしの) 変数名で表して指定。

3.  出力は、いつも新しいデータフレーム。

各動詞は一つのことを上手くやるので、複雑な問題を解くには、複数の動詞を組み合わせる必要があるのが普通です。そ
のために、パイプ`|>`を使います。
パイプについては @sec-the-pipe でさらに議論しますが、簡単に言うと、パイプはその左側からの出力を、その右側の関数に第1引数として渡します。で
すから、`x |> f(y)`は`f(x, y)`と同値であり、`x |> f(y) |> g(z)`は`g(f(x, y), z)`と同値です。
パイプの一番簡単な読み方は、"次に"です。
そう読むと、詳細をまだ学んでいなくても、次のコードが何をしているか、なんとなく分かるでしょう。

```{r}
#| eval: false

flights |>
  filter(dest == "IAH") |> 
  group_by(year, month, day) |> 
  summarize(
    arr_delay = mean(arr_delay, na.rm = TRUE)
  )
```

dplyrの動詞は、**行**、**列**、**グループ**、**テーブル**のどれを演算対象にする4つのグループで構成されています。
以下のセクションでは、行、列、グループのための最も重要な動詞を学習します。デ
ーブルを演算対象にするjoin動詞には、@sec-joins で戻ってきます。
では、はじめましょう。

## 行

データセットの行を演算対象とする動詞で最も大切なのは、順序はそのままに残る行を変える`filter()`と、残る行はそのままに順序を変える`arrange()`です。
どちらの関数も行だけに影響し、列はそのままにします。
ユニークな値の行を見つけ出す`distinct()`も議論しますが、`arrange()`や`filter()`と異なり、オプションとして列も修正することができます。

### `filter()`

`filter()`を使えば、列の値に基づいて行を残すことができます[^data-transform-1]。
第1引数はデータフレーム。
第2引数とその後の引数は、行を残すには真でなければならない条件です。
例えば、120分 (2時間) 超遅れて出発した全ての便を探せます。

[^data-transform-1]: 後ほど、行をその位置に基づいて選べる`slice_*()`類を学習します。

```{r}
flights |> 
  filter(dep_delay > 120)
```

`>` (超) だけでなく、`>=` (以上)、`<` (未満)、`<=` (以下)、`==` (等しい)、`!=` (等しくない)も使えます。
`&`か`,`で条件同士を組み合わせることで"かつ" (両条件が真) の意味にしたり、`|`で組み合わせて"または" (どちらかの条件が真) の意味にしたりできます。

```{r}
# 1月1日の出発便
flights |> 
  filter(month == 1 & day == 1)

# 1月か2月の出発便
flights |> 
  filter(month == 1 | month == 2)
```

`|`と`==`の組み合わせが続く場合、`%in%`というショートカットが役に立ちます。
右側の値のどれか一つと変数の値が等しければ、その行を残します。

```{r}
# 1月か2月の出発便を選ぶショートカットによる方法
flights |> 
  filter(month %in% c(1, 2))
```

これらの比較や論理演算子については、より詳細に @sec-logicals で戻ってきます。

`filter()`を実行すると、dplyrはフィルタ作業を行い、新しいデータフレームを作成、それから、プリントします。
dplyr関数は入力を決して修正しないので、既存の`flights`データセットは修正されません。
結果を保存するには、代入子`<-`を使う必要があります。

```{r}
jan1 <- flights |> 
  filter(month == 1 & day == 1)
```

### よくある間違い

Rを使いはじめた当初に犯しがちな間違いは、等しいかテストする際に、`==`ではなく`=`を使ってしまうことです。
そうした場合、`filter()`はエラーを出して教えてくれます。

```{r}
#| error: true

flights |> 
  filter(month = 1)
```

もう一つよくある間違いは、英語で"or"を書くように、記述してしまうことです。

```{r}
#| eval: false

flights |> 
  filter(month == 1 | 2)
```

エラーは出て来ていないという意味で、これはこれで"機能"しています。し
かし、`|`はまず`month == 1`という条件が真か調べ、次に`2`という意味を成さない条件を調べているので、意図したようには機能していません。
ここで何が起こっているのか、それはなぜなのか、@sec-boolean-operations で学びます。

### `arrange()`

`arrange()`は、列の値に基づいて行の順序を変えます。
引数は、データフレームと、それを基に順序付けする列の名前のセット (もしくは、さらに複雑な表現) です。
列の名前を複数入れると、そこまでの列ではタイだった値を順序付けするために、追加した列は使われます。
例えば、以下のコードは4つの列にまたがっている出発時間でソートします。
まず年の順、次の同じ年の中で月順、などなどとなります。

```{r}
flights |> 
  arrange(year, month, day, dep_time)
```

`arrange()`の中で列を`desc()`に入れると、データフレームをその列の降順で (大きい値から小さい値へ) 並び替えることができます。
例えば、以下のコードは出発遅延時間の最長から最短への順に便を並び替えます。

```{r}
flights |> 
  arrange(desc(dep_delay))
```

行数は変わっていませんね。デ
ータをアレンジしているだけで、フィルタしているわけではないのです。

### `distinct()`

`distinct()`はデータセット内のユニークな行を全て探し出すものです。で
すから、技術的な意味で、第一義的には行を操作します。
しかし、多くの場合、いくつかの変数の組み合わせでユニークな行を探し出したいので、オプションとして列の名前も指定できます。

```{r}
# ダブった行があれば除去
flights |> 
  distinct()

# ユニークな出発地と到着地のペアを全て探し出す
flights |> 
  distinct(origin, dest)
```

その他の列も残したい場合は、`.keep_all = TRUE`オプションを使えます。

```{r}
flights |> 
  distinct(origin, dest, .keep_all = TRUE)
```

これらユニークな便が全て1月1日なのは偶然ではありません。`d`
`istinct()`はデータセット内のユニークな行の一番最初のものを探し出し、残りは捨てています。

ユニークな行ごとに何行あるかカウントしたいのなら、`distinct()`ではなく、`count()`を使って、`sort = TRUE`と引数を指定すると、カウントの降順に並べられます。
`count()`については、@sec-counts でさらに学習します。

```{r}
flights |>
  count(origin, dest, sort = TRUE)
```

### 練習問題

1.  以下の各条件ごとに、パイプを使って、満たす便を全て見つけなさい。

    -   到着遅延が2時間以上
    -   ヒューストン行き (`IAH`か`HOU`)
    -   United、American、Deltaが運営
    -   夏の出発 (7〜9月)
    -   出発遅延はなかったのに、到着時間が2時間超
    -   出発遅延が1時間以上が、飛行中に30分超遅れを取り戻した

2.  `flights`を並べ直して、到着遅延が最も長い便を見つけなさい。
    朝一番早く出発した便を見つけなさい。

3.  `flights`を並べ直して、一番速い便を見つけなさい。
    (ヒント：関数内に算術計算式を入れてみなさい。)

4.  2013年の全ての日に便はあったか？

5.  飛行距離が最も長かった便は？
    短かった便は？

6.  `filter()`と`arrange()`をパイプでつなぐとき、どちらを先にするかで違いはある？
    その理由は？
    結果を想定して、関数がしなければならない作業量を考えてみること。

## 列

行を変えずに列に影響する4つの重要な動詞があります。`m`
`utate()`は既存の列から新しい列を作り出します。`s`
`elect()`は残る列を選びます。`r`
`ename()`は列の名前を変更します。`r`
`elocate()`は列の位置を変えます。

### `mutate()` {#sec-mutate}

`mutate()`の仕事は、既存の列から計算された新しい列を追加することです。
先の変換の部では、変数のデータ型ごとに操作できるよう、関数の大集合を学習します。
ここでは、基本的な算術だけを使って、基本的な算術だけを使って、飛行中に取り戻した遅延時間`gain`や、時速何マイルの`speed`を計算します。

```{r}
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60
  )
```

デフォルトでは、`mutate()`はデータセットの右端に新しい列を追加します。こ
こでは、何が起きているのか見づらいです。
`.before`引数を使って1列目の前と指定すると、左端に追加できます[^data-transform-2]。

[^data-transform-2]: RStudioでは、列数の多いデータセットを見る一番簡単な方法は`View()`を使うことです。

```{r}
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .before = 1
  )
```

`.before`の`.`は、`.before`が関数の引数であって、`gain`や`speed`と並ぶ3つ目の新変数の名前ではないことのサインです。
また、ある変数の後ろに追加したいのなら`.after`が使えます。`.` `before`と`.after`は、位置ではなく変数名で指定できます。
例えば、以下のように`day`の後ろに新変数を追加できます。

```{r}
#| results: false

flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .after = day
  )
```

また、`.keep`引数を使えば、どの変数を残すかコントロールできます。
特に有用なのは`"used"`と指定することで、`mutate()`の中で使った、あるいは、作った列だけを残せます。
例えば、以下の出力は、`dep_delay`、`arr_delay`、`air_time`、`gain`、`hours`と`gain_per_hour`の変数だけになります。

```{r}
#| results: false

flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    hours = air_time / 60,
    gain_per_hour = gain / hours,
    .keep = "used"
  )
```

`flights`に以上の計算結果を代入し直していないので、`gain`、`hours`、`gain_per_hour`の新変数はプリントされているだけで、データフレームには保存されていません。
先で使用するためにデータフレームに保存したい場合、`flights`に代入し直して他にも多数の変数があるオリジナルのデータフレームを上書きするか、新しいオブジェクトに代入するか、注意深く考えるべきです。
普通は、中身が分かりやすい名前、例えば`delay_gain`、を付けた新しいオブジェクトに代入するのが正解です。た
だ、`flights`を上書きする十分な理由がある場合もありえます。

### `select()` {#sec-select}

データセットの変数が数百、いや数千にのぼることは珍しくありません。
こうした場合、まずは興味がある変数にフォーカスすることが挑戦になります。
`select()`を使えば、変数名に基づく操作で有益なサブセットに素早くズームインできます。

-   名前で列を選択。

    ```{r}
    #| results: false

    flights |> 
      select(year, month, day)
    ```

-   `year`から`day`までの (両端を含む) 全ての列を選択。

    ```{r}
    #| results: false

    flights |> 
      select(year:day)
    ```

-   `year`から`day`までの (両端を含む) 全ての列、以外の列を選択。

    ```{r}
    #| results: false

    flights |> 
      select(!year:day)
    ```

    この操作は`!`ではなく`-`を使って操作してきた歴史があるので、`-`を使った操作例がそこかしかに見られます。
    この2つの演算子は同じ目的を果たしますが、動作に微妙な差があります。
    `!`を"not"と読むと、`&`や`|`との組み合わせが馴染むので、`!`の使用をお薦めします。

-   データ型が文字列の全ての列を選択。

    ```{r}
    #| results: false

    flights |> 
      select(where(is.character))
    ```

`select()`の中で使えるヘルパー関数がいくつかあります。

-   `starts_with("abc")`は、名前が"abc"で始まる列。
-   `ends_with("xyz")`は、名前が"xyz"で終わる列。
-   `contains("ijk")`は、名前に"ijk"が含まれる列。
-   `num_range("x", 1:3)`は、名前が`x1`、`x2`、`x3`と一致する列。

さらなる詳細は、`?select`を見てください。
正規表現 (@sec-regular-expressions のトピックです) を知れば、`matches()`を使って、パターンに一致する変数を選べるようになります。

`select()`の中で`=`を使えば、選択と同時に変数名の変更もできます。
変更後の名前を`=`の左側に、変更前の名前を右側にします。

```{r}
flights |> 
  select(tail_num = tailnum)
```

### `rename()`

既存の変数全てを残したいけれど、そのうちの2、3の変数名を変更したい場合、`select()`に替わって、`rename()`が使えます。

```{r}
flights |> 
  rename(tail_num = tailnum)
```

列の名前が首尾一貫しないものが多く、手作業でいちいち修正するのが苦痛な場合、`janitor::clean_names()`を試してみてください。自
動的に名前をクリーンにして、使いやすくしてくれます。

### `relocate()`

`relocate()`を使って、変数の位置を変えられます。
関連する変数を一箇所にまとめたい、あるいは、重要な変数を一番前に持って来たい、ということがあるかもしれません。
デフォルトでは、`relocate()`は変数を一番前に持って来ます。

```{r}
flights |> 
  relocate(time_hour, air_time)
```

`mutate()`で紹介したのと同様に、引数の`.before`や`.after`を使えば、置き場所を指定できます。

```{r}
#| results: false

flights |> 
  relocate(year:dep_time, .after = time_hour)
flights |> 
  relocate(starts_with("arr"), .before = dep_time)
```

### 練習問題

```{r}
#| eval: false
#| echo: false

# For data checking, not used in results shown in book
flights <- flights |> mutate(
  dep_time = hour * 60 + minute,
  arr_time = (arr_time %/% 100) * 60 + (arr_time %% 100),
  airtime2 = arr_time - dep_time,
  dep_sched = dep_time + dep_delay
)

ggplot(flights, aes(x = dep_sched)) + geom_histogram(binwidth = 60)
ggplot(flights, aes(x = dep_sched %% 60)) + geom_histogram(binwidth = 1)
ggplot(flights, aes(x = air_time - airtime2)) + geom_histogram()
```

1.  `dep_time`、`sched_dep_time`、`dep_delay`を比較しなさい。
    これら3つの変数はどういう関係だと思いますか？

2.  `flights`から`dep_time`、`dep_delay`、`arr_time`、`arr_delay`の4つの列を選択する方法を、可能な限り多くブレーンストームしなさい。

3.  `select()`の中で同じ変数を複数回したらどうなりますか？

4.  `any_of()`関数は何をしてくれるのか？
    以下のベクトルと一緒に使うと役立つ理由は？

    ```{r}
    variables <- c("year", "month", "day", "dep_delay", "arr_delay")
    ```

5.  以下コードの実行結果に驚きましたか？
    `select()`のヘルパー関数は、デフォルトでは大文字小文字をどう扱いますか？
    どうすればそのデフォルトと違った動作にできますか？

    ```{r}
    #| eval: false

    flights |> select(contains("TIME"))
    ```

6.  単位を示すため`air_time`を`air_time_min`に変更して、データフレームの一番前に持って来なさい。

7.  以下のコードを機能しない理由は？　
    エラーの意味は？

    ```{r}
    #| error: true

    flights |> 
      select(tailnum) |> 
      arrange(arr_delay)
    ```

## パイプ {#sec-the-pipe}

ここまでパイプの簡単な例を示してきましたが、複数の動詞を組み合わせはじめてこそ、その真の力は発揮されます。
例えば、ヒューストンのIAH空港への最速便を見つけ出したいとすると、以下のように`filter()`、`mutate()`、`select()`、`arrange()`を組み合わせる必要があります。

```{r}
flights |> 
  filter(dest == "IAH") |> 
  mutate(speed = distance / air_time * 60) |> 
  select(year:day, dep_time, carrier, flight, speed) |> 
  arrange(desc(speed))
```

このパイプラインには4つのステップがありますが、動詞が各行の最初に来ているので、ざっと読みやすくなっています。`f`
`lights`データからはじめて、次にfilter、次にmutate、次にselect、次にarrangeという具合です。

パイプがなければ、どうなっていたでしょうか？
各関数が先の関数の出力を呼び出す格好で、入れ子にすることになったでしょう。

```{r}
#| results: false

arrange(
  select(
    mutate(
      filter(
        flights, 
        dest == "IAH"
      ),
      speed = distance / air_time * 60
    ),
    year:day, dep_time, carrier, flight, speed
  ),
  desc(speed)
)
```

もしくは、中間オブジェクトをたくさん使うことになっていたかもしれません。

```{r}
#| results: false

flights1 <- filter(flights, dest == "IAH")
flights2 <- mutate(flights1, speed = distance / air_time * 60)
flights3 <- select(flights2, year:day, dep_time, carrier, flight, speed)
arrange(flights3, desc(speed))
```

両形式とも使いみちはあるものの、一般的にはパイプを使うと、データ分析コードは書くのも読むのも楽になります。

コードにパイプを加えるには、RStudioのキーボード・ショートカット Ctrl/Cmd + Shift + M を使うことをお薦めします。
`%>%`ではなく、`|>`を使うには、 @fig-pipe-options のように、RStudioのオプション設定を一箇所変更する必要があります。`%`
`>%`については、もう少しこの先で述べます。

```{r}
#| label: fig-pipe-options
#| echo: false
#| fig-cap: |
#|   `|>`を挿入するには、"Use native pipe operator"がチェック済みになっていることを確認のこと。
#| fig-alt: | 
#|   "Use native pipe operator"オプションがチェック済みになっている
#|   スクリーンショット。このオプションは、Optionsの"Code"の中の
#|   "Editing"パネルにある。

knitr::include_graphics("screenshots/rstudio-pipe-options.png")
```

::: callout-note
## magrittr

tidyverseをしばらく使っている人なら、**magrittr**パッケージが提供してくれる`%>%`パイプに馴染みがあるでしょう。
magrittrパッケージはtidyverseのコア・パッケージ群の一つなので、tidyverseをロードしていれば`%>%`を使えます。

```{r}
#| eval: false

library(tidyverse)

mtcars %>% 
  group_by(cyl) %>%
  summarize(n = n())
```

簡単な事例では、`|>`も`%>%`も動作は同じです。
だったら、ベースのパイプを薦める理由は？
第1に、ベースRの一部ですから、tidyverseをロードしていないときも含めて、いつでも使えること。
第2に、`%>%`より`|>`の方がずっと簡素であること。`%`
`>%`が発明された2014年とR 4.1.0に`|>`が含められた2021年の間に、パイプの理解が進みました。
おかげで、ベースのパイプでは、ほとんど使われない、あまり重要でない機能を落とすことができました。
:::

## グループ

ここまで、行と列を操作する関数を学んできました。
グループ単位で操作する能力を加えると、dplyrはさらに強力になります。
このセクションでは、`group_by()`、`summarize()`と`slice_`関数群にフォーカスします。

### `group_by()`

`group_by()`を使うと、分析上意味のあるグループにデータセットを分割できます。

```{r}
flights |> 
  group_by(month)
```

`group_by()`ではデータ自体に変化はありませんが、出力をよく見ると、"grouped by" month (`Groups: month [12]`) となっていることに気付きます。
その意味は、ここから先の操作は"by month"で行われる、ということです。
`group_by()`は、このグループ特性 (クラスと呼びます) をデータフレームに加えます。そ
の結果、その先データに適用される動詞の動作が変わります。

### `summarize()` {#sec-summarize}

最も重要なグループ単位の操作は要約です。要
約統計値一つを計算するよう使えば、データフレームはグループごと1行に圧縮されます。
dplyrでは`summarize()`[^data-transform-3]がこの操作を担います。
以下の例では、月ごとの平均出発遅延を計算しています。

[^data-transform-3]: もしくは、英国英語がお好みなら`summarise()`。

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay)
  )
```

おっと！
何かまずいようです。結
果が全て`NA` ("N-A"と読みます) になってしまいました。R
でも欠損値を表します。
こうなったのは、`dep_delay`列に欠損値がある観測がいくつかあったためです。欠
損値込みで平均を計算したので、結果が`NA`になったということです。
欠損値の詳細は、@sec-missing-values で戻ってきますが、ここでは`mean()`で`na.rm` 引数を`TRUE`に設定して欠損値を無視させます。

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE)
  )
```

`summarize()`の中では、複数の要約値を作れます。
先の章で役立つさまざまな要約値を学習しますが、特に役立つのが`n()`で、各グループごとの行数を返します。

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    n = n()
  )
```

平均とカウントを得ることで、データサイエンスで驚くほど先まで進めます！

### `slice_`関数群

5つの手軽な関数で、各グループ内の特定の行を取り出すことができます。

-   `df |> slice_head(n = 1)`は、各グループから最初の行を取り出す。
-   `df |> slice_tail(n = 1)`は、各グループから最後の行を取り出す。
-   `df |> slice_min(x, n = 1)`は、各グループから`x`列の値が最小の行を取り出す。
-   `df |> slice_max(x, n = 1)`は、各グループから`x`列の値が最大の行を取り出す。
-   `df |> slice_sample(n = 1)`は、各グループからランダムに1行を取り出す。

`n`を変えれば1行超の行を取り出せますし、`n =`の替わりに`prop = 0.1`とすれば、各グループから (例えば) 10％の行を取り出せます。
例えば、以下のコードは目的地ごとに到着遅延が最も長かった便を見つけ出しています。

```{r}
flights |> 
  group_by(dest) |> 
  slice_max(arr_delay, n = 1) |>
  relocate(dest)
```

目的地は105なのに、ここには108行もあります。
どうして？
`slice_min()`と`slice_max()`は、値がタイの場合全てを取り出すので、`n = 1`だと最大値の行全てを取り出します。
どうしてもグループごとに1行だけにしたいなら、`with_ties = FALSE`と設定します。

到着遅延の最大値を`summarize()`で計算するのと似ていますが、要約統計値だけではなく、該当する行 (タイがあれば、それも含めて) 全体が得られます。

### Grouping by multiple variables

You can create groups using more than one variable.
For example, we could make a group for each date.

```{r}
daily <- flights |>  
  group_by(year, month, day)
daily
```

When you summarize a tibble grouped by more than one variable, each summary peels off the last group.
In hindsight, this wasn't a great way to make this function work, but it's difficult to change without breaking existing code.
To make it obvious what's happening, dplyr displays a message that tells you how you can change this behavior:

```{r}
daily_flights <- daily |> 
  summarize(n = n())
```

If you're happy with this behavior, you can explicitly request it in order to suppress the message:

```{r}
#| results: false

daily_flights <- daily |> 
  summarize(
    n = n(), 
    .groups = "drop_last"
  )
```

Alternatively, change the default behavior by setting a different value, e.g., `"drop"` to drop all grouping or `"keep"` to preserve the same groups.

### Ungrouping

You might also want to remove grouping from a data frame without using `summarize()`.
You can do this with `ungroup()`.

```{r}
daily |> 
  ungroup()
```

Now let's see what happens when you summarize an ungrouped data frame.

```{r}
daily |> 
  ungroup() |>
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    flights = n()
  )
```

You get a single row back because dplyr treats all the rows in an ungrouped data frame as belonging to one group.

### `.by`

dplyr 1.1.0 includes a new, experimental, syntax for per-operation grouping, the `.by` argument.
`group_by()` and `ungroup()` aren't going away, but you can now also use the `.by` argument to group within a single operation:

```{r}
#| results: false
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = month
  )
```

Or if you want to group by multiple variables:

```{r}
#| results: false
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = c(origin, dest)
  )
```

`.by` works with all verbs and has the advantage that you don't need to use the `.groups` argument to suppress the grouping message or `ungroup()` when you're done.

We didn't focus on this syntax in this chapter because it was very new when we wrote the book.
We did want to mention it because we think it has a lot of promise and it's likely to be quite popular.
You can learn more about it in the [dplyr 1.1.0 blog post](https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-per-operation-grouping/).

### Exercises

1.  Which carrier has the worst average delays?
    Challenge: can you disentangle the effects of bad airports vs. bad carriers?
    Why/why not?
    (Hint: think about `flights |> group_by(carrier, dest) |> summarize(n())`)

2.  Find the flights that are most delayed upon departure from each destination.

3.  How do delays vary over the course of the day.
    Illustrate your answer with a plot.

4.  What happens if you supply a negative `n` to `slice_min()` and friends?

5.  Explain what `count()` does in terms of the dplyr verbs you just learned.
    What does the `sort` argument to `count()` do?

6.  Suppose we have the following tiny data frame:

    ```{r}
    df <- tibble(
      x = 1:5,
      y = c("a", "b", "a", "a", "b"),
      z = c("K", "K", "L", "L", "K")
    )
    ```

    a.  Write down what you think the output will look like, then check if you were correct, and describe what `group_by()` does.

        ```{r}
        #| eval: false
            
        df |>
          group_by(y)
        ```

    b.  Write down what you think the output will look like, then check if you were correct, and describe what `arrange()` does.
        Also comment on how it's different from the `group_by()` in part (a)?

        ```{r}
        #| eval: false
            
        df |>
          arrange(y)
        ```

    c.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.

        ```{r}
        #| eval: false
            
        df |>
          group_by(y) |>
          summarize(mean_x = mean(x))
        ```

    d.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
        Then, comment on what the message says.

        ```{r}
        #| eval: false
            
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x))
        ```

    e.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
        How is the output different from the one in part (d).

        ```{r}
        #| eval: false
            
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x), .groups = "drop")
        ```

    f.  Write down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does.
        How are the outputs of the two pipelines different?

        ```{r}
        #| eval: false
            
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x))
            
        df |>
          group_by(y, z) |>
          mutate(mean_x = mean(x))
        ```

## Case study: aggregates and sample size {#sec-sample-size}

Whenever you do any aggregation, it's always a good idea to include a count (`n()`).
That way, you can ensure that you're not drawing conclusions based on very small amounts of data.
We'll demonstrate this with some baseball data from the **Lahman** package.
Specifically, we will compare what proportion of times a player gets a hit (`H`) vs. the number of times they try to put the ball in play (`AB`):

```{r}
batters <- Lahman::Batting |> 
  group_by(playerID) |> 
  summarize(
    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    n = sum(AB, na.rm = TRUE)
  )
batters
```

When we plot the skill of the batter (measured by the batting average, `performance`) against the number of opportunities to hit the ball (measured by times at bat, `n`), you see two patterns:

1.  The variation in `performance` is larger among players with fewer at-bats.
    The shape of this plot is very characteristic: whenever you plot a mean (or other summary statistics) vs. group size, you'll see that the variation decreases as the sample size increases[^data-transform-4].

2.  There's a positive correlation between skill (`performance`) and opportunities to hit the ball (`n`) because teams want to give their best batters the most opportunities to hit the ball.

[^data-transform-4]: \*cough\* the law of large numbers \*cough\*.

```{r}
#| warning: false
#| fig-alt: |
#|   A scatterplot of number of batting performance vs. batting opportunites 
#|   overlaid with a smoothed line. Average performance increases sharply
#|   from 0.2 at when n is 1 to 0.25 when n is ~1000. Average performance
#|   continues to increase linearly at a much shallower slope reaching
#|   ~0.3 when n is ~15,000.

batters |> 
  filter(n > 100) |> 
  ggplot(aes(x = n, y = performance)) +
  geom_point(alpha = 1 / 10) + 
  geom_smooth(se = FALSE)
```

Note the handy pattern for combining ggplot2 and dplyr.
You just have to remember to switch from `|>`, for dataset processing, to `+` for adding layers to your plot.

This also has important implications for ranking.
If you naively sort on `desc(performance)`, the people with the best batting averages are clearly the ones who tried to put the ball in play very few times and happened to get a hit, they're not necessarily the most skilled players:

```{r}
batters |> 
  arrange(desc(performance))
```

You can find a good explanation of this problem and how to overcome it at <http://varianceexplained.org/r/empirical_bayes_baseball/> and <https://www.evanmiller.org/how-not-to-sort-by-average-rating.html>.

## Summary

In this chapter, you've learned the tools that dplyr provides for working with data frames.
The tools are roughly grouped into three categories: those that manipulate the rows (like `filter()` and `arrange()`, those that manipulate the columns (like `select()` and `mutate()`), and those that manipulate groups (like `group_by()` and `summarize()`).
In this chapter, we've focused on these "whole data frame" tools, but you haven't yet learned much about what you can do with the individual variable.
We'll come back to that in the Transform part of the book, where each chapter will give you tools for a specific type of variable.

In the next chapter, we'll pivot back to workflow to discuss the importance of code style, keeping your code well organized in order to make it easy for you and others to read and understand your code.
