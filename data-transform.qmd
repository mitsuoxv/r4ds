# データ変換 {#sec-data-transform}

```{r}
#| echo: false

source("_common.R")
```

## はじめに

可視化は洞察を得るための大切な道具ですが、描きたいと思うグラフを作成するのにまさに必要な形式でデータを入手することはめったにないことです。
多くの場合、データで質問に答えるために新しい変数や要約を作る必要があります。も
しくは、データを少々扱いやすくするために変数名の変更や観察の並べ替えをしたいこともあります。
これた全て (とさらに！) を本章では学びます。
**dplyr**パッケージと新しく2013年ニューヨーク発航空便データセットを使って、データ変換を紹介します。

本章のゴールはデータフレームを変換する鍵となる道具全てをざっと示すことです。
データフレームの行を操作する関数からはじめて、次に列を操作する関数へ進みます。そ
れから振り返って、動詞を組み合わせるのに使うパイプについてさらに語ります。
次に、グループを扱うやり方を紹介します。
本章の最後は、これらの関数を実際に使う様子を示すケーススタディです。デ
ータ型 (例えば、数値、文字列、日付) ごとに掘り下げる先の章で、振り返って関数の詳細を学びます。

### 準備するもの

本章では、やはりtidyverseのコア・メンバーであるdplyrパッケージにフォーカスします。
nycflights13パッケージのデータを使って鍵となるアイディアを示します。ま
た、データを理解する助けとして、ggplot2パッケージを使います。

```{r}
#| label: setup

library(nycflights13)
library(tidyverse)
```

tidyverseをロードしたときに表示されるコンフリクト・メッセージに注意を払ってください。
dplyrがベースRのいくつかの関数を上書きしていると書いてあります。
dplyrをロード後にベースRのこれらの関数を使いたい場合は、`stats::filter()`や`stats::lag()`のように、関数のフルネームで呼ぶ必要があります。
ここまでは、関数がどのパッケージのものかほぼ無視してきました。た
いていは、どうでもよいからです。
しかし、パッケージを知っていれば、ヘルプを探したり、関連する関数を探したりする助けになります。そ
こで、関数がどのパッケージのものか精確である必要がある場合は、Rと同じ文法の`packagename::functionname()`を使うことにします。

### nycflights13

基礎的なdplyr動詞を試すため、`nycflights13::flights`を使います。
このデータセットには、2013年ニューヨーク市発の全`r format(nrow(nycflights13::flights), big.mark = ",")`飛行便が入っています。
データの出所は、[米国運輸統計局](https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr)で、ドキュメントは`?flights`で見られます。

```{r}
flights
```

`flights`は、よくある落とし穴を避けるためtidyverseが使う、特殊なタイプのデータフレームのtibbleです。
tibbleとデータフレームの最も重要な違いは、どう印刷されるかです。t
ibbleは大きなデータセット向きに設計されているので、行は最初のいくつかだけ、列は一画面に収まる分だけが表示されます。
全てを見る方法はいくつかあります。
RStudioを使っているなら、一番簡単な方法はおそらく`View(flights)`とすることです。イ
ンターアクティブ・ビューのタブが開いて、スクロールやフィルタが可能です。
他の方法としては、`print(flights, width = Inf)`とすれば全列が表示されます。あ
るいは、`glimpse()`とすれば以下のように表示されます。

```{r}
glimpse(flights)
```

どちらの表示でも、変数名の次にあるのは各変数のデータ型の略称です。`<`
`int>`は整数、`<dbl>`は倍精度浮動小数点数 (つまり実数)、`<chr>`は文字 (つまり文字列)、`<dttm>`は日付時間のことです。
変数に対して行える演算は"データ型"によって違うので、これらは大事です。

### dplyrの基本

これから学ぶのは主要なdplyr動詞 (関数) です。こ
れらを使えば、データ操作についての大抵の挑戦は解決できます。
しかし、各動詞の違いを議論する前に、共有していることを述べておいた方が良いでしょう。

1.  第1引数は、いつもデータフレーム。

2.  その次の引数は、典型的には演算対象を (引用符なしの) 変数名で表して指定。

3.  出力は、いつも新しいデータフレーム。

各動詞は一つのことを上手くやるので、複雑な問題を解くには、複数の動詞を組み合わせる必要があるのが普通です。そ
のために、パイプ`|>`を使います。
パイプについては @sec-the-pipe でさらに議論しますが、簡単に言うと、パイプはその左側からの出力を、その右側の関数に第1引数として渡します。で
すから、`x |> f(y)`は`f(x, y)`と同値であり、`x |> f(y) |> g(z)`は`g(f(x, y), z)`と同値です。
パイプの一番簡単な読み方は、"次に"です。
そう読むと、詳細をまだ学んでいなくても、次のコードが何をしているか、なんとなく分かるでしょう。

```{r}
#| eval: false

flights |>
  filter(dest == "IAH") |> 
  group_by(year, month, day) |> 
  summarize(
    arr_delay = mean(arr_delay, na.rm = TRUE)
  )
```

dplyrの動詞は、**行**、**列**、**グループ**、**テーブル**のどれを演算対象にする4つのグループで構成されています。
以下のセクションでは、行、列、グループのための最も重要な動詞を学習します。デ
ーブルを演算対象にするjoin動詞には、@sec-joins で戻ってきます。
では、はじめましょう。

## 行

データセットの行を演算対象とする動詞で最も大切なのは、順序はそのままに残る行を変える`filter()`と、残る行はそのままに順序を変える`arrange()`です。
どちらの関数も行だけに影響し、列はそのままにします。
ユニークな値の行を見つけ出す`distinct()`も議論しますが、`arrange()`や`filter()`と異なり、オプションとして列も修正することができます。

### `filter()`

`filter()`を使えば、列の値に基づいて行を残すことができます[^data-transform-1]。
第1引数はデータフレーム。
第2引数とその後の引数は、行を残すには真でなければならない条件です。
例えば、120分 (2時間) 超遅れて出発した全ての便を探せます。

[^data-transform-1]: 後ほど、行をその位置に基づいて選べる`slice_*()`類を学習します。

```{r}
flights |> 
  filter(dep_delay > 120)
```

`>` (超) だけでなく、`>=` (以上)、`<` (未満)、`<=` (以下)、`==` (等しい)、`!=` (等しくない)も使えます。
`&`か`,`で条件同士を組み合わせることで"かつ" (両条件が真) の意味にしたり、`|`で組み合わせて"または" (どちらかの条件が真) の意味にしたりできます。

```{r}
# 1月1日の出発便
flights |> 
  filter(month == 1 & day == 1)

# 1月か2月の出発便
flights |> 
  filter(month == 1 | month == 2)
```

`|`と`==`の組み合わせが続く場合、`%in%`というショートカットが役に立ちます。
右側の値のどれか一つと変数の値が等しければ、その行を残します。

```{r}
# 1月か2月の出発便を選ぶショートカットによる方法
flights |> 
  filter(month %in% c(1, 2))
```

これらの比較や論理演算子については、より詳細に @sec-logicals で戻ってきます。

`filter()`を実行すると、dplyrはフィルタ作業を行い、新しいデータフレームを作成、それから、プリントします。
dplyr関数は入力を決して修正しないので、既存の`flights`データセットは修正されません。
結果を保存するには、代入子`<-`を使う必要があります。

```{r}
jan1 <- flights |> 
  filter(month == 1 & day == 1)
```

### よくある間違い

Rを使いはじめた当初に犯しがちな間違いは、等しいかテストする際に、`==`ではなく`=`を使ってしまうことです。
そうした場合、`filter()`はエラーを出して教えてくれます。

```{r}
#| error: true

flights |> 
  filter(month = 1)
```

もう一つよくある間違いは、英語で"or"を書くように、記述してしまうことです。

```{r}
#| eval: false

flights |> 
  filter(month == 1 | 2)
```

エラーは出て来ていないという意味で、これはこれで"機能"しています。し
かし、`|`はまず`month == 1`という条件が真か調べ、次に`2`という意味を成さない条件を調べているので、意図したようには機能していません。
ここで何が起こっているのか、それはなぜなのか、@sec-boolean-operations で学びます。

### `arrange()`

`arrange()`は、列の値に基づいて行の順序を変えます。
引数は、データフレームと、それを基に順序付けする列の名前のセット (もしくは、さらに複雑な表現) です。
列の名前を複数入れると、そこまでの列ではタイだった値を順序付けするために、追加した列は使われます。
例えば、以下のコードは4つの列にまたがっている出発時間でソートします。
まず年の順、次の同じ年の中で月順、などなどとなります。

```{r}
flights |> 
  arrange(year, month, day, dep_time)
```

`arrange()`の中で列を`desc()`に入れると、データフレームをその列の降順で (大きい値から小さい値へ) 並び替えることができます。
例えば、以下のコードは出発遅延時間の最長から最短への順に便を並び替えます。

```{r}
flights |> 
  arrange(desc(dep_delay))
```

行数は変わっていませんね。デ
ータをアレンジしているだけで、フィルタしているわけではないのです。

### `distinct()`

`distinct()`はデータセット内のユニークな行を全て探し出すものです。で
すから、技術的な意味で、第一義的には行を操作します。
しかし、多くの場合、いくつかの変数の組み合わせでユニークな行を探し出したいので、オプションとして列の名前も指定できます。

```{r}
# ダブった行があれば除去
flights |> 
  distinct()

# ユニークな出発地と到着地のペアを全て探し出す
flights |> 
  distinct(origin, dest)
```

その他の列も残したい場合は、`.keep_all = TRUE`オプションを使えます。

```{r}
flights |> 
  distinct(origin, dest, .keep_all = TRUE)
```

これらユニークな便が全て1月1日なのは偶然ではありません。`d`
`istinct()`はデータセット内のユニークな行の一番最初のものを探し出し、残りは捨てています。

ユニークな行ごとに何行あるかカウントしたいのなら、`distinct()`ではなく、`count()`を使って、`sort = TRUE`と引数を指定すると、カウントの降順に並べられます。
`count()`については、@sec-counts でさらに学習します。

```{r}
flights |>
  count(origin, dest, sort = TRUE)
```

### 練習問題

1.  以下の各条件ごとに、パイプを使って、満たす便を全て見つけなさい。

    -   到着遅延が2時間以上
    -   ヒューストン行き (`IAH`か`HOU`)
    -   United、American、Deltaが運営
    -   夏の出発 (7〜9月)
    -   出発遅延はなかったのに、到着時間が2時間超
    -   出発遅延が1時間以上が、飛行中に30分超遅れを取り戻した

2.  `flights`を並べ直して、到着遅延が最も長い便を見つけなさい。
    朝一番早く出発した便を見つけなさい。

3.  `flights`を並べ直して、一番速い便を見つけなさい。
    (ヒント：関数内に算術計算式を入れてみなさい。)

4.  2013年の全ての日に便はあったか？

5.  飛行距離が最も長かった便は？
    短かった便は？

6.  `filter()`と`arrange()`をパイプでつなぐとき、どちらを先にするかで違いはある？
    その理由は？
    結果を想定して、関数がしなければならない作業量を考えてみること。

## 列

行を変えずに列に影響する4つの重要な動詞があります。`m`
`utate()`は既存の列から新しい列を作り出します。`s`
`elect()`は残る列を選びます。`r`
`ename()`は列の名前を変更します。`r`
`elocate()`は列の位置を変えます。

### `mutate()` {#sec-mutate}

`mutate()`の仕事は、既存の列から計算された新しい列を追加することです。
先の変換の部では、変数のデータ型ごとに操作できるよう、関数の大集合を学習します。
ここでは、基本的な算術だけを使って、基本的な算術だけを使って、飛行中に取り戻した遅延時間`gain`や、時速何マイルの`speed`を計算します。

```{r}
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60
  )
```

デフォルトでは、`mutate()`はデータセットの右端に新しい列を追加します。こ
こでは、何が起きているのか見づらいです。
`.before`引数を使って1列目の前と指定すると、左端に追加できます[^data-transform-2]。

[^data-transform-2]: RStudioでは、列数の多いデータセットを見る一番簡単な方法は`View()`を使うことです。

```{r}
flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .before = 1
  )
```

`.before`の`.`は、`.before`が関数の引数であって、`gain`や`speed`と並ぶ3つ目の新変数の名前ではないことのサインです。
また、ある変数の後ろに追加したいのなら`.after`が使えます。`.` `before`と`.after`は、位置ではなく変数名で指定できます。
例えば、以下のように`day`の後ろに新変数を追加できます。

```{r}
#| results: false

flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .after = day
  )
```

また、`.keep`引数を使えば、どの変数を残すかコントロールできます。
特に有用なのは`"used"`と指定することで、`mutate()`の中で使った、あるいは、作った列だけを残せます。
例えば、以下の出力は、`dep_delay`、`arr_delay`、`air_time`、`gain`、`hours`と`gain_per_hour`の変数だけになります。

```{r}
#| results: false

flights |> 
  mutate(
    gain = dep_delay - arr_delay,
    hours = air_time / 60,
    gain_per_hour = gain / hours,
    .keep = "used"
  )
```

`flights`に以上の計算結果を代入し直していないので、`gain`、`hours`、`gain_per_hour`の新変数はプリントされているだけで、データフレームには保存されていません。
先で使用するためにデータフレームに保存したい場合、`flights`に代入し直して他にも多数の変数があるオリジナルのデータフレームを上書きするか、新しいオブジェクトに代入するか、注意深く考えるべきです。
普通は、中身が分かりやすい名前、例えば`delay_gain`、を付けた新しいオブジェクトに代入するのが正解です。た
だ、`flights`を上書きする十分な理由がある場合もありえます。

### `select()` {#sec-select}

It's not uncommon to get datasets with hundreds or even thousands of variables.
In this situation, the first challenge is often just focusing on the variables you're interested in.
`select()` allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:

-   Select columns by name:

    ```{r}
    #| results: false

    flights |> 
      select(year, month, day)
    ```

-   Select all columns between year and day (inclusive):

    ```{r}
    #| results: false

    flights |> 
      select(year:day)
    ```

-   Select all columns except those from year to day (inclusive):

    ```{r}
    #| results: false

    flights |> 
      select(!year:day)
    ```

    Historically this operation was done with `-` instead of `!`, so you're likely to see that in the wild.
    These two operators serve the same purpose but with subtle differences in behavior.
    We recommend using `!` because it reads as "not" and combines well with `&` and `|`.

-   Select all columns that are characters:

    ```{r}
    #| results: false

    flights |> 
      select(where(is.character))
    ```

There are a number of helper functions you can use within `select()`:

-   `starts_with("abc")`: matches names that begin with "abc".
-   `ends_with("xyz")`: matches names that end with "xyz".
-   `contains("ijk")`: matches names that contain "ijk".
-   `num_range("x", 1:3)`: matches `x1`, `x2` and `x3`.

See `?select` for more details.
Once you know regular expressions (the topic of @sec-regular-expressions) you'll also be able to use `matches()` to select variables that match a pattern.

You can rename variables as you `select()` them by using `=`.
The new name appears on the left hand side of the `=`, and the old variable appears on the right hand side:

```{r}
flights |> 
  select(tail_num = tailnum)
```

### `rename()`

If you want to keep all the existing variables and just want to rename a few, you can use `rename()` instead of `select()`:

```{r}
flights |> 
  rename(tail_num = tailnum)
```

If you have a bunch of inconsistently named columns and it would be painful to fix them all by hand, check out `janitor::clean_names()` which provides some useful automated cleaning.

### `relocate()`

Use `relocate()` to move variables around.
You might want to collect related variables together or move important variables to the front.
By default `relocate()` moves variables to the front:

```{r}
flights |> 
  relocate(time_hour, air_time)
```

You can also specify where to put them using the `.before` and `.after` arguments, just like in `mutate()`:

```{r}
#| results: false

flights |> 
  relocate(year:dep_time, .after = time_hour)
flights |> 
  relocate(starts_with("arr"), .before = dep_time)
```

### Exercises

```{r}
#| eval: false
#| echo: false

# For data checking, not used in results shown in book
flights <- flights |> mutate(
  dep_time = hour * 60 + minute,
  arr_time = (arr_time %/% 100) * 60 + (arr_time %% 100),
  airtime2 = arr_time - dep_time,
  dep_sched = dep_time + dep_delay
)

ggplot(flights, aes(x = dep_sched)) + geom_histogram(binwidth = 60)
ggplot(flights, aes(x = dep_sched %% 60)) + geom_histogram(binwidth = 1)
ggplot(flights, aes(x = air_time - airtime2)) + geom_histogram()
```

1.  Compare `dep_time`, `sched_dep_time`, and `dep_delay`.
    How would you expect those three numbers to be related?

2.  Brainstorm as many ways as possible to select `dep_time`, `dep_delay`, `arr_time`, and `arr_delay` from `flights`.

3.  What happens if you specify the name of the same variable multiple times in a `select()` call?

4.  What does the `any_of()` function do?
    Why might it be helpful in conjunction with this vector?

    ```{r}
    variables <- c("year", "month", "day", "dep_delay", "arr_delay")
    ```

5.  Does the result of running the following code surprise you?
    How do the select helpers deal with upper and lower case by default?
    How can you change that default?

    ```{r}
    #| eval: false

    flights |> select(contains("TIME"))
    ```

6.  Rename `air_time` to `air_time_min` to indicate units of measurement and move it to the beginning of the data frame.

7.  Why doesn't the following work, and what does the error mean?

    ```{r}
    #| error: true

    flights |> 
      select(tailnum) |> 
      arrange(arr_delay)
    ```

## The pipe {#sec-the-pipe}

We've shown you simple examples of the pipe above, but its real power arises when you start to combine multiple verbs.
For example, imagine that you wanted to find the fastest flights to Houston's IAH airport: you need to combine `filter()`, `mutate()`, `select()`, and `arrange()`:

```{r}
flights |> 
  filter(dest == "IAH") |> 
  mutate(speed = distance / air_time * 60) |> 
  select(year:day, dep_time, carrier, flight, speed) |> 
  arrange(desc(speed))
```

Even though this pipeline has four steps, it's easy to skim because the verbs come at the start of each line: start with the `flights` data, then filter, then mutate, then select, then arrange.

What would happen if we didn't have the pipe?
We could nest each function call inside the previous call:

```{r}
#| results: false

arrange(
  select(
    mutate(
      filter(
        flights, 
        dest == "IAH"
      ),
      speed = distance / air_time * 60
    ),
    year:day, dep_time, carrier, flight, speed
  ),
  desc(speed)
)
```

Or we could use a bunch of intermediate objects:

```{r}
#| results: false

flights1 <- filter(flights, dest == "IAH")
flights2 <- mutate(flights1, speed = distance / air_time * 60)
flights3 <- select(flights2, year:day, dep_time, carrier, flight, speed)
arrange(flights3, desc(speed))
```

While both forms have their time and place, the pipe generally produces data analysis code that is easier to write and read.

To add the pipe to your code, we recommend using the built-in keyboard shortcut Ctrl/Cmd + Shift + M.
You'll need to make one change to your RStudio options to use `|>` instead of `%>%` as shown in @fig-pipe-options; more on `%>%` shortly.

```{r}
#| label: fig-pipe-options
#| echo: false
#| fig-cap: |
#|   To insert `|>`, make sure the "Use native pipe operator" option is checked.
#| fig-alt: | 
#|   Screenshot showing the "Use native pipe operator" option which can
#|   be found on the "Editing" panel of the "Code" options.

knitr::include_graphics("screenshots/rstudio-pipe-options.png")
```

::: callout-note
## magrittr

If you've been using the tidyverse for a while, you might be familiar with the `%>%` pipe provided by the **magrittr** package.
The magrittr package is included in the core tidyverse, so you can use `%>%` whenever you load the tidyverse:

```{r}
#| eval: false

library(tidyverse)

mtcars %>% 
  group_by(cyl) %>%
  summarize(n = n())
```

For simple cases, `|>` and `%>%` behave identically.
So why do we recommend the base pipe?
Firstly, because it's part of base R, it's always available for you to use, even when you're not using the tidyverse.
Secondly, `|>` is quite a bit simpler than `%>%`: in the time between the invention of `%>%` in 2014 and the inclusion of `|>` in R 4.1.0 in 2021, we gained a better understanding of the pipe.
This allowed the base implementation to jettison infrequently used and less important features.
:::

## Groups

So far you've learned about functions that work with rows and columns.
dplyr gets even more powerful when you add in the ability to work with groups.
In this section, we'll focus on the most important functions: `group_by()`, `summarize()`, and the slice family of functions.

### `group_by()`

Use `group_by()` to divide your dataset into groups meaningful for your analysis:

```{r}
flights |> 
  group_by(month)
```

`group_by()` doesn't change the data but, if you look closely at the output, you'll notice that the output indicates that it is "grouped by" month (`Groups: month [12]`).
This means subsequent operations will now work "by month".
`group_by()` adds this grouped feature (referred to as class) to the data frame, which changes the behavior of the subsequent verbs applied to the data.

### `summarize()` {#sec-summarize}

The most important grouped operation is a summary, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group.
In dplyr, this operation is performed by `summarize()`[^data-transform-3], as shown by the following example, which computes the average departure delay by month:

[^data-transform-3]: Or `summarise()`, if you prefer British English.

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay)
  )
```

Uhoh!
Something has gone wrong and all of our results are `NA`s (pronounced "N-A"), R's symbol for missing value.
This happened because some of the observed flights had missing data in the delay column, and so when we calculated the mean including those values, we got an `NA` result.
We'll come back to discuss missing values in detail in @sec-missing-values, but for now we'll tell the `mean()` function to ignore all missing values by setting the argument `na.rm` to `TRUE`:

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE)
  )
```

You can create any number of summaries in a single call to `summarize()`.
You'll learn various useful summaries in the upcoming chapters, but one very useful summary is `n()`, which returns the number of rows in each group:

```{r}
flights |> 
  group_by(month) |> 
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    n = n()
  )
```

Means and counts can get you a surprisingly long way in data science!

### The `slice_` functions

There are five handy functions that allow you extract specific rows within each group:

-   `df |> slice_head(n = 1)` takes the first row from each group.
-   `df |> slice_tail(n = 1)` takes the last row in each group.
-   `df |> slice_min(x, n = 1)` takes the row with the smallest value of column `x`.
-   `df |> slice_max(x, n = 1)` takes the row with the largest value of column `x`.
-   `df |> slice_sample(n = 1)` takes one random row.

You can vary `n` to select more than one row, or instead of `n =`, you can use `prop = 0.1` to select (e.g.) 10% of the rows in each group.
For example, the following code finds the flights that are most delayed upon arrival at each destination:

```{r}
flights |> 
  group_by(dest) |> 
  slice_max(arr_delay, n = 1) |>
  relocate(dest)
```

Note that there are 105 destinations but we get 108 rows here.
What's up?
`slice_min()` and `slice_max()` keep tied values so `n = 1` means give us all rows with the highest value.
If you want exactly one row per group you can set `with_ties = FALSE`.

This is similar to computing the max delay with `summarize()`, but you get the whole corresponding row (or rows if there's a tie) instead of the single summary statistic.

### Grouping by multiple variables

You can create groups using more than one variable.
For example, we could make a group for each date.

```{r}
daily <- flights |>  
  group_by(year, month, day)
daily
```

When you summarize a tibble grouped by more than one variable, each summary peels off the last group.
In hindsight, this wasn't a great way to make this function work, but it's difficult to change without breaking existing code.
To make it obvious what's happening, dplyr displays a message that tells you how you can change this behavior:

```{r}
daily_flights <- daily |> 
  summarize(n = n())
```

If you're happy with this behavior, you can explicitly request it in order to suppress the message:

```{r}
#| results: false

daily_flights <- daily |> 
  summarize(
    n = n(), 
    .groups = "drop_last"
  )
```

Alternatively, change the default behavior by setting a different value, e.g., `"drop"` to drop all grouping or `"keep"` to preserve the same groups.

### Ungrouping

You might also want to remove grouping from a data frame without using `summarize()`.
You can do this with `ungroup()`.

```{r}
daily |> 
  ungroup()
```

Now let's see what happens when you summarize an ungrouped data frame.

```{r}
daily |> 
  ungroup() |>
  summarize(
    avg_delay = mean(dep_delay, na.rm = TRUE), 
    flights = n()
  )
```

You get a single row back because dplyr treats all the rows in an ungrouped data frame as belonging to one group.

### `.by`

dplyr 1.1.0 includes a new, experimental, syntax for per-operation grouping, the `.by` argument.
`group_by()` and `ungroup()` aren't going away, but you can now also use the `.by` argument to group within a single operation:

```{r}
#| results: false
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = month
  )
```

Or if you want to group by multiple variables:

```{r}
#| results: false
flights |> 
  summarize(
    delay = mean(dep_delay, na.rm = TRUE), 
    n = n(),
    .by = c(origin, dest)
  )
```

`.by` works with all verbs and has the advantage that you don't need to use the `.groups` argument to suppress the grouping message or `ungroup()` when you're done.

We didn't focus on this syntax in this chapter because it was very new when we wrote the book.
We did want to mention it because we think it has a lot of promise and it's likely to be quite popular.
You can learn more about it in the [dplyr 1.1.0 blog post](https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-per-operation-grouping/).

### Exercises

1.  Which carrier has the worst average delays?
    Challenge: can you disentangle the effects of bad airports vs. bad carriers?
    Why/why not?
    (Hint: think about `flights |> group_by(carrier, dest) |> summarize(n())`)

2.  Find the flights that are most delayed upon departure from each destination.

3.  How do delays vary over the course of the day.
    Illustrate your answer with a plot.

4.  What happens if you supply a negative `n` to `slice_min()` and friends?

5.  Explain what `count()` does in terms of the dplyr verbs you just learned.
    What does the `sort` argument to `count()` do?

6.  Suppose we have the following tiny data frame:

    ```{r}
    df <- tibble(
      x = 1:5,
      y = c("a", "b", "a", "a", "b"),
      z = c("K", "K", "L", "L", "K")
    )
    ```

    a.  Write down what you think the output will look like, then check if you were correct, and describe what `group_by()` does.

        ```{r}
        #| eval: false
            
        df |>
          group_by(y)
        ```

    b.  Write down what you think the output will look like, then check if you were correct, and describe what `arrange()` does.
        Also comment on how it's different from the `group_by()` in part (a)?

        ```{r}
        #| eval: false
            
        df |>
          arrange(y)
        ```

    c.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.

        ```{r}
        #| eval: false
            
        df |>
          group_by(y) |>
          summarize(mean_x = mean(x))
        ```

    d.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
        Then, comment on what the message says.

        ```{r}
        #| eval: false
            
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x))
        ```

    e.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.
        How is the output different from the one in part (d).

        ```{r}
        #| eval: false
            
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x), .groups = "drop")
        ```

    f.  Write down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does.
        How are the outputs of the two pipelines different?

        ```{r}
        #| eval: false
            
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x))
            
        df |>
          group_by(y, z) |>
          mutate(mean_x = mean(x))
        ```

## Case study: aggregates and sample size {#sec-sample-size}

Whenever you do any aggregation, it's always a good idea to include a count (`n()`).
That way, you can ensure that you're not drawing conclusions based on very small amounts of data.
We'll demonstrate this with some baseball data from the **Lahman** package.
Specifically, we will compare what proportion of times a player gets a hit (`H`) vs. the number of times they try to put the ball in play (`AB`):

```{r}
batters <- Lahman::Batting |> 
  group_by(playerID) |> 
  summarize(
    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    n = sum(AB, na.rm = TRUE)
  )
batters
```

When we plot the skill of the batter (measured by the batting average, `performance`) against the number of opportunities to hit the ball (measured by times at bat, `n`), you see two patterns:

1.  The variation in `performance` is larger among players with fewer at-bats.
    The shape of this plot is very characteristic: whenever you plot a mean (or other summary statistics) vs. group size, you'll see that the variation decreases as the sample size increases[^data-transform-4].

2.  There's a positive correlation between skill (`performance`) and opportunities to hit the ball (`n`) because teams want to give their best batters the most opportunities to hit the ball.

[^data-transform-4]: \*cough\* the law of large numbers \*cough\*.

```{r}
#| warning: false
#| fig-alt: |
#|   A scatterplot of number of batting performance vs. batting opportunites 
#|   overlaid with a smoothed line. Average performance increases sharply
#|   from 0.2 at when n is 1 to 0.25 when n is ~1000. Average performance
#|   continues to increase linearly at a much shallower slope reaching
#|   ~0.3 when n is ~15,000.

batters |> 
  filter(n > 100) |> 
  ggplot(aes(x = n, y = performance)) +
  geom_point(alpha = 1 / 10) + 
  geom_smooth(se = FALSE)
```

Note the handy pattern for combining ggplot2 and dplyr.
You just have to remember to switch from `|>`, for dataset processing, to `+` for adding layers to your plot.

This also has important implications for ranking.
If you naively sort on `desc(performance)`, the people with the best batting averages are clearly the ones who tried to put the ball in play very few times and happened to get a hit, they're not necessarily the most skilled players:

```{r}
batters |> 
  arrange(desc(performance))
```

You can find a good explanation of this problem and how to overcome it at <http://varianceexplained.org/r/empirical_bayes_baseball/> and <https://www.evanmiller.org/how-not-to-sort-by-average-rating.html>.

## Summary

In this chapter, you've learned the tools that dplyr provides for working with data frames.
The tools are roughly grouped into three categories: those that manipulate the rows (like `filter()` and `arrange()`, those that manipulate the columns (like `select()` and `mutate()`), and those that manipulate groups (like `group_by()` and `summarize()`).
In this chapter, we've focused on these "whole data frame" tools, but you haven't yet learned much about what you can do with the individual variable.
We'll come back to that in the Transform part of the book, where each chapter will give you tools for a specific type of variable.

In the next chapter, we'll pivot back to workflow to discuss the importance of code style, keeping your code well organized in order to make it easy for you and others to read and understand your code.
