# 探索的データ分析 {#sec-exploratory-data-analysis}

```{r}
#| echo: false

source("_common.R")
```

## はじめに

本章では、可視化と変換を使って、統計学者が探索的データ分析 (略してEDA) と呼ぶ、データを探索する組織立った方法を示します。
EDAは反復サイクルです。
あなたは、

1.  データについて質問を生成します。

2.  データを可視化、変換、モデル化して、回答を探します。

3.  分かったことを使って質問を精錬させる、もしくは、新しい質問を生成する。

EDAは厳格な規則集がある正式な過程ではありません。
EDAは何よりもまず、心の持ち様なのです。
EDAの初期段階では思いついた全てのアイディアを気ままに調査すべきです。
いくつかのアイディアは広がり、またいくつかのアイディアは行き詰まります。
探索を続けるうちに、2、3の特に実りある洞察を行き着き、最終的には報告書を書き上げて他者に伝達することになります。

EDAはどんなデータ分析でも重要な部分です。た
とえ、研究の第一義的な質問が盆に載せて手渡されたとしても、データ品質を調べる必要が常にある以上、EDAは欠かせません。
データ・クリーニングはEDAの一つの応用に過ぎません。デ
ータが期待に沿うものか否かの質問にあたります。
データ・クリーニングを行うには、可視化、変換、モデル化といったEDAの全ての道具を持ち出す必要があります。

### 準備するもの

本章では、dplyrとggplot2について学習したことを組み合わせて、質問を尋ね、データを使って回答、そしてまた新しい質問を尋ねることを繰り返します。

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

## 質問

> "決まりきった統計上の質問などない。あるのは疑わしい統計の決まりきった手順だけだ。" --- Sir David Cox

> "間違った質問への常に精密にできる正確な回答よりも、正しい質問への大まかでたいてい曖昧な回答の方がずっと良い。" --- John Tukey

EDAでのゴールはデータの理解を深めることです。
最も簡単な方法は、質問を道具として使って、調査を導くことです。
質問を尋ねると、データセットの特定の部分に注意を集中でき、どのグラフ、モデル、もしくは、変換を作成すべきか決める助けになります。

EDAは基本的に創造的過程です。
ほとんどの創造的過程と同様、*高品質の*質問を尋ねる鍵となるのは、*大量の*質問を生成することです。
分析をはじめたときは、データセットからどんな洞察を拾い集められるのか知らないので、何かを明らかにする質問を尋ねることは困難です。
他方、新しい質問を尋ねるたびにデータの新しい側面が見えてきて、何かを発見する機会が増えていきます。
見つけたことに基づいて質問に質問を重ねることで、データの最も興味深い部分に素早く潜り込み、示唆に富む質問集を作り出せるのです。

研究を導くのにどの質問を尋ねるべきか、には規則はありません。
ただ、データから何かを発見するのに、2つのタイプの質問がいつも役に立ちます。
それらの質問を緩く文章にすると以下のような感じです。

1.  変数内の変動は、どのタイプ？

2.  変数間の共変動は、どのタイプ？

本章の残りの部分は、これら2つの質問を見ていきます。
変動や共変動が何かを説明して、各質問に回答するいくつかの方法を示します。

## 変動

**変動**は、変数の値が測定ごとに変化する傾向です。
実生活で変動を見ることは簡単です。ど
んな連続変数でも2度測定すれば、結果は違っているでしょう。
たとえ光速のような一定の量を測定したとしても、同様です。
測定ごとに小さな誤差を含んでおり、それは測定ごとに違っているからです。
また、異なる対象 (例えば、異なる人々の眼の色) や、異なる時点 (例えば、異なる瞬間での電子のエネルギー水準) で測定すれば、変数は異なります。
全ての変数には独自の変動のパターンがあり、同じ観測での、あるいは、異なる観測間の、測定ごとの変動の仕方について興味深い情報が明らかになりえます。
パターンを理解する最良の方法は、@sec-data-visualization 学習した、変数値分布の可視化です。

`diamonds`データセットから約54,000個のダイアモンドの重さ (`carat`) の分布を可視化することから探索をはじめましょう。
`carat`は数値変数なので、ヒストグラムが使えます。

```{r}
#| fig-alt: |
#|   ダイアモンドのカラットのヒストグラム。x軸は0から4.5、y軸は0から30000の
#|   範囲。分布は右に長く延びており、0が真ん中のビンに入るダイアモンドは
#|   とても少なく、0.5が真ん中のビンには30000近いダイアモンドが入り、
#|   1が真ん中のビンには約15000のダイアモンドが入り、1.5が真ん中のビンには
#|   ずっと少ない約5000のダイアモンドが入る。そこからは、長く尾を引く。

ggplot(diamonds, aes(x = carat)) +
  geom_histogram(binwidth = 0.5)
```

変動を可視化できたところで、プロットの中に何を探すべきでしょうか？
どうゆうタイプの質問を、続けて尋ねるべきでしょうか？
グラフの中から探す最も役立つ情報のタイプと、情報のタイプごとに続けるべき質問のいくつか、をこの先でリストにまとめています。
続けて尋ねる質問を良いものにする鍵は、好奇心 (さらに何を知りたいか？) と懐疑心 (どうにか誤解を招いていないか？) に頼ることです。

### 典型的な値

棒グラフでもヒストグラムでも、高い棒は変数のよくある値を示し、低い棒はあまりない値を示します。
棒がない場所からは、データの中に見られない値だと分かります。
この情報を役立つ質問に変えるには、何であれ予期せぬことを探します。

-   どの値が最もありふれているか？
    その理由は？

-   どの値がまれか？
    その理由は？
    予期した通りだった？

-   変わったパターンは見られないか？
    どう説明が付く？

大きいのを除いたダイアモンドの`carat`分布を見てみましょう。

```{r}
#| fig-alt: |
#|   ダイアモンドのカラットのヒストグラム。x軸は0から3、y軸は0から約2500の
#|   範囲。ビン幅がとても狭い (0.01) ので、ひょろっとした棒がとても多数
#|   並んでいる。分布は右に長く延びる形で、多くのピークの後には高さが減少する
#|   棒が続き、次のピークで急増する。

smaller <- diamonds |> 
  filter(carat < 3)

ggplot(smaller, aes(x = carat)) +
  geom_histogram(binwidth = 0.01)
```

このヒストグラムからは、いくつか興味深い質問が示唆されます。

-   カラットが整数、あるいは、よくある分数で、ダイアモンドが多いのはなぜか？

-   各ピークのやや左側よりもやや右側の方が、ダイアモンドが多いのはなぜか？

可視化はまた、データの中にサブグループが存在することを示唆する、クラスターを明らかにできます。
サブグループを理解するには、次のように尋ねます。

-   各サブグループ内の観測がお互いに似ているのはなぜか？

-   サブグループ間の観測がお互いにどう違っているか？

-   クラスターをどう説明、もしくは、描写できるか？

-   クラスターらしきものが誤解を招いているとしたらなぜか？

これらの質問のいくつかはデータから回答できますが、いくつかはデータに関する専門知識が必要になります。
これら質問の多くは、例えば、ある変数の値が別の変数の動きを説明できないか、といった変数*間*の関係を探索するよう促します。
少し先でそれを探索します。

### 外れ値

外れ値は、普通でない観測です。そ
のデータ点はパターンにフィットしていなさそうです。
外れ値は、データ入力エラーであることも、このデータ収集でたまたま観測された極端な値というだけのこともありますが、そうでないときは重要な新発見を示唆しています。
大量のデータがある場合、外れ値はヒストグラムでは見づらいことがあります。
例えば、diamondsデータセットの変数yの分布をヒストグラムで見てみましょう。
外れ値があることの証拠は、x軸の範囲が異常に広いことだけです。

```{r}
#| fig-alt: |
#|   ダイアモンドの幅のヒストグラム。x軸は0から60、y軸は0から12000の範囲。
#|   5辺りにピークが一つあり、データはピークの周りに完全に集中している
#|   ように見える。

ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5)
```

よくあるビンの中の観測はとても多いので、珍しいビンは非常に短くなっていて、とても見づらくなっています (0をじっと凝視すれば何かあると気付くでしょうが)。
異常値を見やすくするには、`coord_cartesian()`を使って、y軸の小さな値にズームする必要があります。

```{r}
#| fig-alt: |
#|   ダイアモンドの幅のヒストグラム。x軸は0から60、y軸は0から12000の範囲。
#|   5辺りにピークが一つあり、データはピークの周りに完全に集中している
#|   ように見える。それらのデータ以外に、0に高さ約8ののビンが一つ、
#|   30を少し超えた所に高さ1のビンが一つ、
#|   60の少し手前にもう一つ高さ1のビンがある。

ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```

`coord_cartesian()`には、x軸にズームするのに必要な`xlim`引数もあります。
ggplot2には関数の`xlim()`と`ylim()`もありますが、挙動が変わります。範
囲外のデータを投げ捨ててしまいます。
このグラフで、異常値が3つ、0と30辺り、60辺りにあることが見えます。
dplyrを使って、引き抜いてみましょう。

```{r}
#| include: false

old <- options(tibble.print_max = 10, tibble.print_min = 10)
```

```{r}
unusual <- diamonds |> 
  filter(y < 3 | y > 20) |> 
  select(price, x, y, z) |>
  arrange(y)
unusual
```

```{r}
#| include: false

options(old)
```

変数`y`は、ダイアモンドを測定した3次元の一つで、ミリ単位なのです。
幅がゼロミリのダイアモンドなんてありえませんから、これらの値は間違いに違いありません。

By doing EDA, we have discovered missing data that was coded as 0, which we never would have found by simply searching for `NA`s.
Going forward we might choose to re-code these values as `NA`s in order to prevent misleading calculations.
We might also suspect that measurements of 32mm and 59mm are implausible: those diamonds are over an inch long, but don't cost hundreds of thousands of dollars!

It's good practice to repeat your analysis with and without the outliers.
If they have minimal effect on the results, and you can't figure out why they're there, it's reasonable to omit them, and move on.
However, if they have a substantial effect on your results, you shouldn't drop them without justification.
You'll need to figure out what caused them (e.g., a data entry error) and disclose that you removed them in your write-up.

### Exercises

1.  Explore the distribution of each of the `x`, `y`, and `z` variables in `diamonds`.
    What do you learn?
    Think about a diamond and how you might decide which dimension is the length, width, and depth.

2.  Explore the distribution of `price`.
    Do you discover anything unusual or surprising?
    (Hint: Carefully think about the `binwidth` and make sure you try a wide range of values.)

3.  How many diamonds are 0.99 carat?
    How many are 1 carat?
    What do you think is the cause of the difference?

4.  Compare and contrast `coord_cartesian()` vs. `xlim()` or `ylim()` when zooming in on a histogram.
    What happens if you leave `binwidth` unset?
    What happens if you try and zoom so only half a bar shows?

## 異常値 {#sec-unusual-values-eda}

If you've encountered unusual values in your dataset, and simply want to move on to the rest of your analysis, you have two options.

1.  Drop the entire row with the strange values:

    ```{r}
    #| eval: false

    diamonds2 <- diamonds |> 
      filter(between(y, 3, 20))
    ```

    We don't recommend this option because one invalid value doesn't imply that all the other values for that observation are also invalid.
    Additionally, if you have low quality data, by the time that you've applied this approach to every variable you might find that you don't have any data left!

2.  Instead, we recommend replacing the unusual values with missing values.
    The easiest way to do this is to use `mutate()` to replace the variable with a modified copy.
    You can use the `if_else()` function to replace unusual values with `NA`:

    ```{r}
    diamonds2 <- diamonds |> 
      mutate(y = if_else(y < 3 | y > 20, NA, y))
    ```

It's not obvious where you should plot missing values, so ggplot2 doesn't include them in the plot, but it does warn that they've been removed:

```{r}
#| dev: "png"
#| fig-alt: |
#|   A scatterplot of widths vs. lengths of diamonds. There is a strong, 
#|   linear association between the two variables. All but one of the diamonds 
#|   has length greater than 3. The one outlier has a length of 0 and a width 
#|   of about 6.5. 

ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point()
```

To suppress that warning, set `na.rm = TRUE`:

```{r}
#| eval: false

ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point(na.rm = TRUE)
```

Other times you want to understand what makes observations with missing values different to observations with recorded values.
For example, in `nycflights13::flights`[^eda-1], missing values in the `dep_time` variable indicate that the flight was cancelled.
So you might want to compare the scheduled departure times for cancelled and non-cancelled times.
You can do this by making a new variable, using `is.na()` to check if `dep_time` is missing.

[^eda-1]: Remember that when we need to be explicit about where a function (or dataset) comes from, we'll use the special form `package::function()` or `package::dataset`.

```{r}
#| fig-alt: |
#|   A frequency polygon of scheduled departure times of flights. Two lines 
#|   represent flights that are cancelled and not cancelled. The x-axis ranges 
#|   from 0 to 25 minutes and the y-axis ranges from 0 to 10000. The number of 
#|   flights not cancelled are much higher than those cancelled.

nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time)) + 
  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)
```

However this plot isn't great because there are many more non-cancelled flights than cancelled flights.
In the next section we'll explore some techniques for improving this comparison.

### Exercises

1.  What happens to missing values in a histogram?
    What happens to missing values in a bar chart?
    Why is there a difference in how missing values are handled in histograms and bar charts?

2.  What does `na.rm = TRUE` do in `mean()` and `sum()`?

3.  Recreate the frequency plot of `scheduled_dep_time` colored by whether the flight was cancelled or not.
    Also facet by the `cancelled` variable.
    Experiment with different values of the `scales` variable in the faceting function to mitigate the effect of more non-cancelled flights than cancelled flights.

## Covariation

If variation describes the behavior *within* a variable, covariation describes the behavior *between* variables.
**Covariation** is the tendency for the values of two or more variables to vary together in a related way.
The best way to spot covariation is to visualize the relationship between two or more variables.

### A categorical and a numerical variable {#sec-cat-num}

For example, let's explore how the price of a diamond varies with its quality (measured by `cut`) using `geom_freqpoly()`:

```{r}
#| fig-alt: |
#|   A frequency polygon of prices of diamonds where each cut of carat (Fair, 
#|   Good, Very Good, Premium, and Ideal) is represented with a different color 
#|   line. The x-axis ranges from 0 to 30000 and the y-axis ranges from 0 to 
#|   5000. The lines overlap a great deal, suggesting similar frequency 
#|   distributions of prices of diamonds. One notable feature is that 
#|   Ideal diamonds have the highest peak around 1500.

ggplot(diamonds, aes(x = price)) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```

Note that ggplot2 uses an ordered color scale for `cut` because it's defined as an ordered factor variable in the data.
You'll learn more about these in @sec-ordered-factors.

The default appearance of `geom_freqpoly()` is not that useful here because the height, determined by the overall count, differs so much across `cut`s, making it hard to see the differences in the shapes of their distributions.

To make the comparison easier we need to swap what is displayed on the y-axis.
Instead of displaying count, we'll display the **density**, which is the count standardized so that the area under each frequency polygon is one.

```{r}
#| fig-alt: |
#|   A frequency polygon of densities of prices of diamonds where each cut of 
#|   carat (Fair, Good, Very Good, Premium, and Ideal) is represented with a 
#|   different color line. The x-axis ranges from 0 to 20000. The lines overlap 
#|   a great deal, suggesting similar density distributions of prices of 
#|   diamonds. One notable feature is that all but Fair diamonds have high peaks 
#|   around a price of 1500 and Fair diamonds have a higher mean than others.

ggplot(diamonds, aes(x = price, y = after_stat(density))) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```

Note that we're mapping the density to `y`, but since `density` is not a variable in the `diamonds` dataset, we need to first calculate it.
We use the `after_stat()` function to do so.

There's something rather surprising about this plot - it appears that fair diamonds (the lowest quality) have the highest average price!
But maybe that's because frequency polygons are a little hard to interpret - there's a lot going on in this plot.

A visually simpler plot for exploring this relationship is using side-by-side boxplots.

```{r}
#| fig-alt: |
#|   Side-by-side boxplots of prices of diamonds by cut. The distribution of 
#|   prices is right skewed for each cut (Fair, Good, Very Good, Premium, and 
#|   Ideal). The medians are close to each other, with the median for Ideal 
#|   diamonds lowest and that for Fair highest.

ggplot(diamonds, aes(x = cut, y = price)) +
  geom_boxplot()
```

We see much less information about the distribution, but the boxplots are much more compact so we can more easily compare them (and fit more on one plot).
It supports the counter-intuitive finding that better quality diamonds are typically cheaper!
In the exercises, you'll be challenged to figure out why.

`cut` is an ordered factor: fair is worse than good, which is worse than very good and so on.
Many categorical variables don't have such an intrinsic order, so you might want to reorder them to make a more informative display.
One way to do that is with `fct_reorder()`.
You'll learn more about that function in @sec-modifying-factor-order, but we want to give you a quick preview here because it's so useful.
For example, take the `class` variable in the `mpg` dataset.
You might be interested to know how highway mileage varies across classes:

```{r}
#| fig-alt: |
#|   Side-by-side boxplots of highway mileages of cars by class. Classes are 
#|   on the x-axis (2seaters, compact, midsize, minivan, pickup, subcompact, 
#|   and suv).

ggplot(mpg, aes(x = class, y = hwy)) +
  geom_boxplot()
```

To make the trend easier to see, we can reorder `class` based on the median value of `hwy`:

```{r}
#| fig-alt: |
#|   Side-by-side boxplots of highway mileages of cars by class. Classes are 
#|   on the x-axis and ordered by increasing median highway mileage (pickup, 
#|   suv, minivan, 2seater, subcompact, compact, and midsize).

ggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +
  geom_boxplot()
```

If you have long variable names, `geom_boxplot()` will work better if you flip it 90°.
You can do that by exchanging the x and y aesthetic mappings.

```{r}
#| fig-alt: |
#|   Side-by-side boxplots of highway mileages of cars by class. Classes are 
#|   on the y-axis and ordered by increasing median highway mileage.

ggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +
  geom_boxplot()
```

#### Exercises

1.  Use what you've learned to improve the visualization of the departure times of cancelled vs. non-cancelled flights.

2.  Based on EDA, what variable in the diamonds dataset appears to be most important for predicting the price of a diamond?
    How is that variable correlated with cut?
    Why does the combination of those two relationships lead to lower quality diamonds being more expensive?

3.  Instead of exchanging the x and y variables, add `coord_flip()` as a new layer to the vertical boxplot to create a horizontal one.
    How does this compare to exchanging the variables?

4.  One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of "outlying values".
    One approach to remedy this problem is the letter value plot.
    Install the lvplot package, and try using `geom_lv()` to display the distribution of price vs. cut.
    What do you learn?
    How do you interpret the plots?

5.  Create a visualization of diamond prices vs. a categorical variable from the `diamonds` dataset using `geom_violin()`, then a faceted `geom_histogram()`, then a colored `geom_freqpoly()`, and then a colored `geom_density()`.
    Compare and contrast the four plots.
    What are the pros and cons of each method of visualizing the distribution of a numerical variable based on the levels of a categorical variable?

6.  If you have a small dataset, it's sometimes useful to use `geom_jitter()` to avoid overplotting to more easily see the relationship between a continuous and categorical variable.
    The ggbeeswarm package provides a number of methods similar to `geom_jitter()`.
    List them and briefly describe what each one does.

### Two categorical variables

To visualize the covariation between categorical variables, you'll need to count the number of observations for each combination of levels of these categorical variables.
One way to do that is to rely on the built-in `geom_count()`:

```{r}
#| fig-alt: |
#|   A scatterplot of color vs. cut of diamonds. There is one point for each
#|   combination of levels of cut (Fair, Good, Very Good, Premium, and Ideal) 
#|   and color (D, E, F, G, G, I, and J). The sizes of the points represent 
#|   the number of observations for that combination. The legend indicates 
#|   that these sizes range between 1000 and 4000.

ggplot(diamonds, aes(x = cut, y = color)) +
  geom_count()
```

The size of each circle in the plot displays how many observations occurred at each combination of values.
Covariation will appear as a strong correlation between specific x values and specific y values.

Another approach for exploring the relationship between these variables is computing the counts with dplyr:

```{r}
diamonds |> 
  count(color, cut)
```

Then visualize with `geom_tile()` and the fill aesthetic:

```{r}
#| fig-alt: |
#|   A tile plot of cut vs. color of diamonds. Each tile represents a 
#|   cut/color combination and tiles are colored according to the number of 
#|   observations in each tile. There are more Ideal diamonds than other cuts, 
#|   with the highest number being Ideal diamonds with color G. Fair diamonds 
#|   and diamonds with color I are the lowest in frequency.

diamonds |> 
  count(color, cut) |>  
  ggplot(aes(x = color, y = cut)) +
  geom_tile(aes(fill = n))
```

If the categorical variables are unordered, you might want to use the seriation package to simultaneously reorder the rows and columns in order to more clearly reveal interesting patterns.
For larger plots, you might want to try the heatmaply package, which creates interactive plots.

#### Exercises

1.  How could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?

2.  What different data insights do you get with a segmented bar chart if color is mapped to the `x` aesthetic and `cut` is mapped to the `fill` aesthetic?
    Calculate the counts that fall into each of the segments.

3.  Use `geom_tile()` together with dplyr to explore how average flight departure delays vary by destination and month of year.
    What makes the plot difficult to read?
    How could you improve it?

### Two numerical variables

You've already seen one great way to visualize the covariation between two numerical variables: draw a scatterplot with `geom_point()`.
You can see covariation as a pattern in the points.
For example, you can see a positive relationship between the carat size and price of a diamond: diamonds with more carats have a higher price.
The relationship is exponential.

```{r}
#| dev: "png"
#| fig-alt: |
#|   A scatterplot of price vs. carat. The relationship is positive, somewhat 
#|   strong, and exponential.

ggplot(smaller, aes(x = carat, y = price)) +
  geom_point()
```

(In this section we'll use the `smaller` dataset to stay focused on the bulk of the diamonds that are smaller than 3 carats)

Scatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black, making it hard to judge differences in the density of the data across the 2-dimensional space as well as making it hard to spot the trend.
You've already seen one way to fix the problem: using the `alpha` aesthetic to add transparency.

```{r}
#| dev: "png"
#| fig-alt: |
#|   A scatterplot of price vs. carat. The relationship is positive, somewhat 
#|   strong, and exponential. The points are transparent, showing clusters where 
#|   the number of points is higher than other areas, The most obvious clusters 
#|   are for diamonds with 1, 1.5, and 2 carats.

ggplot(smaller, aes(x = carat, y = price)) + 
  geom_point(alpha = 1 / 100)
```

But using transparency can be challenging for very large datasets.
Another solution is to use bin.
Previously you used `geom_histogram()` and `geom_freqpoly()` to bin in one dimension.
Now you'll learn how to use `geom_bin2d()` and `geom_hex()` to bin in two dimensions.

`geom_bin2d()` and `geom_hex()` divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin.
`geom_bin2d()` creates rectangular bins.
`geom_hex()` creates hexagonal bins.
You will need to install the hexbin package to use `geom_hex()`.

```{r}
#| layout-ncol: 2
#| fig-width: 3
#| fig-alt: |
#|   Plot 1: A binned density plot of price vs. carat. Plot 2: A hexagonal bin 
#|   plot of price vs. carat. Both plots show that the highest density of 
#|   diamonds have low carats and low prices.

ggplot(smaller, aes(x = carat, y = price)) +
  geom_bin2d()

# install.packages("hexbin")
ggplot(smaller, aes(x = carat, y = price)) +
  geom_hex()
```

Another option is to bin one continuous variable so it acts like a categorical variable.
Then you can use one of the techniques for visualizing the combination of a categorical and a continuous variable that you learned about.
For example, you could bin `carat` and then for each group, display a boxplot:

```{r}
#| fig-alt: |
#|   Side-by-side box plots of price by carat. Each box plot represents diamonds 
#|   that are 0.1 carats apart in weight. The box plots show that as carat 
#|   increases the median price increases as well. Additionally, diamonds with 
#|   1.5 carats or lower have right skewed price distributions, 1.5 to 2 have 
#|   roughly symmetric price distributions, and diamonds that weigh more have 
#|   left skewed distributions. Cheaper, smaller diamonds have outliers on the 
#|   higher end, more expensive, bigger diamonds have outliers on the lower end.

ggplot(smaller, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_width(carat, 0.1)))
```

`cut_width(x, width)`, as used above, divides `x` into bins of width `width`.
By default, boxplots look roughly the same (apart from number of outliers) regardless of how many observations there are, so it's difficult to tell that each boxplot summaries a different number of points.
One way to show that is to make the width of the boxplot proportional to the number of points with `varwidth = TRUE`.

#### Exercises

1.  Instead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon.
    What do you need to consider when using `cut_width()` vs. `cut_number()`?
    How does that impact a visualization of the 2d distribution of `carat` and `price`?

2.  Visualize the distribution of `carat`, partitioned by `price`.

3.  How does the price distribution of very large diamonds compare to small diamonds?
    Is it as you expect, or does it surprise you?

4.  Combine two of the techniques you've learned to visualize the combined distribution of cut, carat, and price.

5.  Two dimensional plots reveal outliers that are not visible in one dimensional plots.
    For example, some points in the following plot have an unusual combination of `x` and `y` values, which makes the points outliers even though their `x` and `y` values appear normal when examined separately.
    Why is a scatterplot a better display than a binned plot for this case?

    ```{r}
    #| eval: false
    diamonds |> 
      filter(x >= 4) |> 
      ggplot(aes(x = x, y = y)) +
      geom_point() +
      coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
    ```

6.  Instead of creating boxes of equal width with `cut_width()`, we could create boxes that contain roughly equal number of points with `cut_number()`.
    What are the advantages and disadvantages of this approach?

    ```{r}
    #| eval: false
    ggplot(smaller, aes(x = carat, y = price)) + 
      geom_boxplot(aes(group = cut_number(carat, 20)))
    ```

## Patterns and models

If a systematic relationship exists between two variables it will appear as a pattern in the data.
If you spot a pattern, ask yourself:

-   Could this pattern be due to coincidence (i.e. random chance)?

-   How can you describe the relationship implied by the pattern?

-   How strong is the relationship implied by the pattern?

-   What other variables might affect the relationship?

-   Does the relationship change if you look at individual subgroups of the data?

Patterns in your data provide clues about relationships, i.e., they reveal covariation.
If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it.
If two variables covary, you can use the values of one variable to make better predictions about the values of the second.
If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.

Models are a tool for extracting patterns out of data.
For example, consider the diamonds data.
It's hard to understand the relationship between cut and price, because cut and carat, and carat and price are tightly related.
It's possible to use a model to remove the very strong relationship between price and carat so we can explore the subtleties that remain.
The following code fits a model that predicts `price` from `carat` and then computes the residuals (the difference between the predicted value and the actual value).
The residuals give us a view of the price of the diamond, once the effect of carat has been removed.
Note that instead of using the raw values of `price` and `carat`, we log transform them first, and fit a model to the log-transformed values.
Then, we exponentiate the residuals to put them back in the scale of raw prices.

```{r}
#| message: false
#| dev: "png"
#| fig-alt: |
#|   A scatterplot of residuals vs. carat of diamonds. The x-axis ranges from 0 
#|   to 5, the y-axis ranges from 0 to almost 4. Much of the data are clustered 
#|   around low values of carat and residuals. There is a clear, curved pattern 
#|   showing decrease in residuals as carat increases.

library(tidymodels)

diamonds <- diamonds |>
  mutate(
    log_price = log(price),
    log_carat = log(carat)
  )

diamonds_fit <- linear_reg() |>
  fit(log_price ~ log_carat, data = diamonds)

diamonds_aug <- augment(diamonds_fit, new_data = diamonds) |>
  mutate(.resid = exp(.resid))

ggplot(diamonds_aug, aes(x = carat, y = .resid)) + 
  geom_point()
```

Once you've removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive.

```{r}
#| fig-alt: |
#|   Side-by-side box plots of residuals by cut. The x-axis displays the various 
#|   cuts (Fair to Ideal), the y-axis ranges from 0 to almost 5. The medians are 
#|   quite similar, between roughly 0.75 to 1.25. Each of the distributions of 
#|   residuals is right skewed, with many outliers on the higher end.

ggplot(diamonds_aug, aes(x = cut, y = .resid)) + 
  geom_boxplot()
```

We're not discussing modelling in this book because understanding what models are and how they work is easiest once you have tools of data wrangling and programming in hand.

## Summary

In this chapter you've learned a variety of tools to help you understand the variation within your data.
You've seen techniques that work with a single variable at a time and with a pair of variables.
This might seem painfully restrictive if you have tens or hundreds of variables in your data, but they're the foundation upon which all other techniques are built.

In the next chapter, we'll focus on the tools we can use to communicate our results.
